{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf184509",
   "metadata": {},
   "source": [
    "# All functions combined\n",
    "### January 19th\n",
    " - Update the brand  / make function to work from make_orig and then concatenate - includes updating the dictionaries ect\n",
    " - Further small amends\n",
    "### December 7th\n",
    "- transfered to live\n",
    "- succesful full run through\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70bb240",
   "metadata": {},
   "source": [
    "# Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f788decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from operator import itemgetter\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from openpyxl import load_workbook\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "from openpyxl import load_workbook  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4d234",
   "metadata": {},
   "source": [
    "## Defining dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f71e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_dict = {'3t ' : '3t',\t'6ku ' : '6ku',\t'6ku barcelona ' : '6ku',\t'6kutype ' : '6ku',\t'activ ' : 'activ',\t'ad0 ' : 'ad0',\t'aero ' : 'aero',\t'airborne ' : 'airborne',\t'airdrop ' : 'airdrop',\t'airnimal ' : 'airnimal',\t'airwalk ' : 'airwalk',\t'airwheel ' : 'airwheel',\t'allegro ' : 'allegro',\t'altra ' : 'altra',\t'ammaco ' : 'ammaco',\t'ancheer ' : 'ancheer',\t'animal ' : 'animal',\t'apex ' : 'apex',\t'aphelion ' : 'aphelion',\t'aplollo ' : 'apollo',\t'apollo ' : 'apollo',\t'apollo jewel ' : 'apollo',\t'apollocustom-built ' : 'apollo',\t'apollonon-domestic product ' : 'apollo',\t'apollotype ' : 'apollo',\t'appollo ' : 'apollo',\t'appolo ' : 'apollo',\t'arcona ' : 'arcona',\t'arden ' : 'arden',\t'argon 18 ' : 'argon 18',\t'argon 18custom-built ' : 'argon 18custom-built',\t'ashton ' : 'ashton',\t'atlas royal ' : 'atlas royal',\t'aurai ' : 'aurai',\t'avanti ' : 'avanti',\t'avenir ' : 'avenir',\t'averton ' : 'averton',\t'b twin ' : 'b twin',\t'b-twin ' : 'b twin',\t'b.twin ' : 'b twin',\t\"b'twin\" : 'b twin',\t'b‚äôtwin ' : 'b twin',\t'b‚äôtwintype ' : 'b twin',\t'banana ' : 'banana',\t'banana bikeean ' : 'banana',\t'banshee ' : 'banshee',\t'barracuda ' : 'barracuda',\t'barracudatype ' : 'barracuda',\t'basis ' : 'basis',\t'basistype ' : 'basis',\t'basso ' : 'basso',\t'batavus ' : 'batavus',\t'batsel ' : 'batsel',\t'bbf ' : 'bbf',\t'belte ' : 'belte',\t'bergamont ' : 'bergamont',\t'bianchi ' : 'bianchi',\t'bianchigender ' : 'bianchi',\t'bickerton ' : 'bickerton',\t'bike bros ' : 'bike bros',\t'birtech ' : 'birtech',\t'bmc ' : 'bmc',\t'boardman ' : 'boardman',\t'boardmancustom-built ' : 'boardman',\t'boardmantype ' : 'boardman',\t'bob jackson ' : 'bob jackson',\t'bobbin ' : 'bobbin',\t'boradman ' : 'boardman',\t'boss ' : 'boss',\t'bradley wiggins ' : 'bradley wiggins',\t'breeze ' : 'breeze',\t'brian rourke ' : 'brian rourke',\t'brighton bicycle company ' : 'brighton bicycle company',\t'british eagle ' : 'british eagle',\t'brodie ' : 'brodie',\t'brompton ' : 'brompton',\t'bromptontype ' : 'brompton',\t'bronx ' : 'bronx',\t'brother cycles ' : 'brother cycles',\t'bsa ' : 'bsa',\t'bsd ' : 'bsd',\t'btwin ' : 'b twin',\t'bull ' : 'bulls',\t'bulls ' : 'bulls',\t'butler claud ' : 'claud butler',\t'calibre ' : 'calibre',\t'calibretype ' : 'calibre',\t'campingsurvivals ' : 'campingsurvivals',\t'cannondale ' : 'cannondale',\t'cannondalestyle ' : 'cannondale',\t'cannondaletype ' : 'cannondale',\t'canondale ' : 'cannondale',\t'canyon ' : 'canyon',\t'canyontype ' : 'canyon',\t'careera ' : 'carrera',\t'carera ' : 'carrera',\t'carerra ' : 'carrera',\t'carlton ' : 'carlton',\t'carrara ' : 'carrera',\t'carrea ' : 'carrera',\t'carrer0 ' : 'carrera',\t'carrera ' : 'carrera',\t'carrera subway 1 ' : 'carrera',\t'carreracustom-built ' : 'carrera',\t'carreratype ' : 'carrera',\t'carrerea  ' : 'carrera',\t'carrerra ' : 'carrera',\t'cboardman ' : 'boardman',\t'ceepo ' : 'ceepo',\t'ceres ' : 'ceres',\t'cerv√©lo ' : 'cervelo',\t'cervelo ' : 'cervelo',\t'cervélo ' : 'cervelo',\t'cervélocustom-built ' : 'cervelo',\t'challenge ' : 'challenge',\t'champ ' : 'champ',\t'charge ' : 'charge',\t'charge bikes ' : 'charge',\t'charger ' : 'charge',\t'chas roberts ' : 'chas roberts',\t'chesterton ' : 'chesterton',\t'chillafish ' : 'chillafish',\t'christine ' : 'christine',\t'cinelli ' : 'cinelli',\t'cinellitype ' : 'cinelli',\t'cipollini ' : 'cipollini',\t'citypro ' : 'citypro',\t'claud butler ' : 'claud butler',\t'claud butlercustom-built ' : 'claud butler',\t'claud buttler ' : 'claud butler',\t'claudbutler ' : 'claud butler',\t'claude butler ' : 'claud butler',\t'claude buttler ' : 'claud butler',\t'club ' : 'club',\t'cobra-bike ' : 'cobra-bike',\t'collective ' : 'collective',\t'colnago ' : 'colnago',\t'colnagotype ' : 'colnago',\t'colorado ' : 'colorado',\t'coloradocustom-built ' : 'colorado',\t'commencal ' : 'commencal',\t'commencalcustom-built ' : 'commencal',\t'compass ' : 'compass',\t'concept ' : 'concept',\t'condor ' : 'condor',\t'continental gp 5000 ' : 'continental gp 5000',\t'coppi ' : 'coppi',\t'cosmos kenda ' : 'cosmos kenda',\t'cotic ' : 'cotic',\t'cove ' : 'cove',\t'coventry eagle ' : 'coventry eagle',\t'cowboy ' : 'cowboy',\t'coyote ' : 'coyote',\t'coyotetype ' : 'coyote',\t'creme ' : 'creme',\t'cross ' : 'cross',\t'cross crf300 ' : 'cross',\t'crosstype ' : 'cross',\t'crown ' : 'crown',\t'crusader ' : 'crusader',\t'cryusher ' : 'cryusher',\t'cube ' : 'cube',\t'cubetype ' : 'cube',\t'cuda ' : 'cuda',\t'cudatype ' : 'cuda',\t'cult ' : 'cult',\t'custom ' : 'custom',\t'cyco ' : 'cyco',\t'd7 ' : 'd7',\t'dahon ' : 'dahon',\t'dahontype' : 'dahon',\t'dakar ' : 'dakar',\t'dartmoor ' : 'dartmoor',\t'dave yates ' : 'dave yates',\t'dawes ' : 'dawes',\t'dawes duchess burguny 2021 ' : 'dawes',\t'dawestype ' : 'dawes',\t'daws ' : 'dawes',\t'de rosa ' : 'de rosa',\t'decathalon ' : 'decathlon',\t'decathlon ' : 'decathlon',\t'decathlon elops ' : 'decathlon',\t'derosa ' : 'de rosa',\t'diamond back ' : 'diamondback',\t'diamondback ' : 'diamondback',\t'dino ' : 'dino',\t'dino bikes ' : 'dino',\t'dinoitem height ' : 'dino',\t'disney ' : 'disney',\t'dmr ' : 'dmr',\t'dolan ' : 'dolan',\t'dragon ' : 'dragon',\t'drb ' : 'drb',\t'dunelt ' : 'dunelt',\t'dunlop ' : 'dunlop',\t'dutch ' : 'dutch',\t'dutchie ' : 'dutchie',\t'early rider ' : 'early rider',\t'easton ' : 'easton',\t'eastway ' : 'eastway',\t'easy rider ' : 'easy rider',\t'ebco ' : 'ebco',\t'eco ' : 'eco',\t'ecosmo ' : 'ecosmo',\t'eddie merckx ' : 'eddie merckx',\t'eddy merckx ' : 'eddy merckx',\t'edinburgh cycles ' : 'edinburgh cycles',\t'electra ' : 'electra',\t'elite products ' : 'elite products',\t'elliptigo ' : 'elliptigo',\t'ellis briggs ' : 'ellis briggs',\t'ellswick ' : 'ellswick',\t'ellsworth ' : 'ellsworth',\t'elops ' : 'elops',\t'elswick ' : 'elswick',\t'emelle ' : 'emmelle',\t'emmelle ' : 'emmelle',\t'energy ' : 'energy',\t'energy enigma 75 ' : 'enigma',\t'engwe ' : 'engwe',\t'enigma ' : 'enigma',\t'etnies ' : 'etnies',\t'eurobike ' : 'eurobike',\t'evans cycles ' : 'evans cycles',\t'evans cycles trend ' : 'evans cycles',\t'everlast ' : 'everlast',\t'eviltype ' : 'eviltype',\t'excel ' : 'excel',\t'extreme ' : 'extreme',\t'factor ' : 'factor',\t'fag ' : 'fag',\t'fairlight ' : 'fairlight',\t'falcon ' : 'falcon',\t'falconcustom-built ' : 'falcon',\t'falcontype ' : 'falcon',\t'federal ' : 'federal',\t'felt ' : 'felt',\t'ferrari ' : 'ferrari',\t'festka ' : 'festka',\t'fiido ' : 'fiido',\t'finether ' : 'finether',\t'firefox festival se ' : 'firefox festival se',\t'first bike ' : 'first bike',\t'fitbikeco. ' : 'fitbikeco.',\t'flanders ' : 'flanders',\t'flit ' : 'flit',\t'flite ' : 'flite',\t'flitetype ' : 'flite',\t'flow ' : 'flow',\t'flying scot ' : 'flying scot',\t'focus ' : 'focus',\t'foffa ' : 'foffa',\t'fondriest ' : 'fondriest',\t'forme ' : 'forme',\t'formetype ' : 'forme',\t'frappe ' : 'frappe',\t'freddie grubb ' : 'freddie grubb',\t'free spirit ' : 'freespirit',\t'freego ' : 'freego',\t'freespirit ' : 'freespirit',\t'freespirittype ' : 'freespirit',\t'frog ' : 'frog bikes',\t'frog bikes ' : 'frog bikes',\t'fudge ' : 'fudge',\t'fuji ' : 'fuji',\t'fujitype ' : 'fuji',\t'gaint ' : 'giant',\t'gary fisher ' : 'gary fisher',\t'gazelle ' : 'gazelle',\t'gemini ' : 'gemini',\t'genesis ' : 'genesis',\t'genisis ' : 'genesis',\t'genissis ' : 'genesis',\t'genissis ' : 'genesis',\t'ghost ' : 'ghost',\t'ghost amr 5900 ' : 'ghost',\t'giant ' : 'giant',\t'giant live ' : 'giant',\t'giant talon ' : 'giant',\t'giantcustom-built ' : 'giant',\t'gianttype ' : 'giant',\t'gillott ' : 'gillott',\t'gitane ' : 'gitane',\t'goku ' : 'goku',\t'gonex ' : 'gonex',\t'graham weigh ' : 'graham weigh',\t'greatchoicehub ' : 'greatchoicehub',\t'gt ' : 'gt',\t'gt pantera ' : 'gt',\t'gttype ' : 'gt',\t'hackney cycles ' : 'hackney cycles',\t'haibike ' : 'haibike',\t'halfbike ' : 'halfbike',\t'halfords ' : 'halfords',\t'haro ' : 'haro',\t'harry quinn ' : 'harry quinn',\t'hawk ' : 'hawk',\t'helliot ' : 'helliot',\t'hercules ' : 'hercules',\t'hetchins ' : 'hetchins',\t'hoffman ' : 'hoffman',\t'holdsworth ' : 'holdsworth',\t'hope ' : 'hope',\t'hoy ' : 'hoy',\t'huffy ' : 'huffy',\t'humber ' : 'humber',\t'hurcules ' : 'hurcules',\t'hurrecane ' : 'hurrecane',\t'ibistype ' : 'ibistype',\t'identiti ' : 'identiti',\t'idk ' : 'idk',\t'imperial ' : 'imperial',\t'indi ' : 'indi',\t'indur ' : 'indur',\t'integra ' : 'integra',\t'intense ' : 'intense',\t'iron horse ' : 'iron horse',\t'isla ' : 'islabikes',\t'islabike ' : 'islabikes',\t'islabikes ' : 'islabikes',\t'jack taylor ' : 'jack taylor',\t'jacques anquetil ' : 'jacques anquetil',\t'jamis ' : 'jamis',\t'jamistype ' : 'jamistype',\t'java ' : 'java',\t'joe waugh ' : 'joe waugh',\t'johnny loco ' : 'johnny loco',\t'jorvik ' : 'jorvik',\t'juletpin ' : 'juletpin',\t'juliana mountain bikes ' : 'juliana',\t'kalkhoff ' : 'kalkhoff',\t'karakoram ' : 'karakoram',\t'kawasaki ' : 'kawasaki',\t'kent ' : 'kent',\t'kettler ' : 'kettler',\t'khe ' : 'khe',\t'khs ' : 'khs',\t'kiddimoto ' : 'kiddimoto',\t'kinesis ' : 'kinesis',\t'kingston ' : 'kingston',\t'kink ' : 'kink',\t'kink industries ' : 'kink',\t'kirk ' : 'kirk',\t'klein ' : 'klein',\t'knights ' : 'knights',\t'koga ' : 'koga',\t'kokua ' : 'kokua',\t'kona ' : 'kona',\t'konatype ' : 'kona',\t'kuota ' : 'kuota',\t'kustom bikes ' : 'kustom bikes',\t'kuwahara ' : 'kuwahara',\t'land rover ' : 'land rover',\t'landrover ' : 'landrover',\t'lapierre ' : 'lapierre',\t'lappiere ' : 'lapierre',\t'laura trott ' : 'laura trott',\t'lectro ' : 'lectro',\t'legnano ' : 'legnano',\t'lemond ' : 'lemond',\t'level ' : 'level',\t'li-fe ' : 'li-fe',\t'lightspeed ' : 'litespeed',\t'lincoln ' : 'lincoln',\t'linus ' : 'linus',\t'litespeed ' : 'litespeed',\t'little big bikes ' : 'little big bikes',\t'liv ' : 'liv',\t'locomotief ' : 'locomotief',\t'lol fun ' : 'lol fun',\t'lombardo ' : 'lombardo',\t'look ' : 'look',\t'lynskey ' : 'lynskey',\t'maclean ' : 'maclean',\t'madison ' : 'madison',\t'mafia ' : 'mafiabikes',\t'mafia bike ' : 'mafiabikes',\t'mafiabike ' : 'mafiabikes',\t'mafiabikes ' : 'mafiabikes',\t'mafiabiketype ' : 'mafiabikes',\t'mango ' : 'mango',\t'maple leaf ' : 'maple leaf',\t'marin ' : 'marin',\t'marino ' : 'marino',\t'marintype ' : 'marin',\t'marlboro ' : 'marlboro',\t'mason ' : 'mason',\t'massi ' : 'massi',\t'mate ' : 'mate',\t'mbk ' : 'mbk',\t'mbm ' : 'mbm',\t'mekk ' : 'mekk',\t'mercedes-benz ' : 'mercedes-benz',\t'mercian ' : 'mercian',\t'mercier ' : 'mercier',\t'merida ' : 'merida',\t'merlin ' : 'merlin',\t'mezzo ' : 'mezzo',\t'mikashima ' : 'mikashima (mks)',\t'mikashima (mks) ' : 'mikashima (mks)',\t'mini ' : 'mini',\t'mirra ' : 'mirra',\t'mizani ' : 'mizani',\t'mobo ' : 'mobo',\t'moda ' : 'moda',\t'mondraker ' : 'mondraker',\t'mongoose ' : 'mongoose',\t'monster truck ' : 'monster truck',\t'montague ' : 'montague',\t'monteria ' : 'monteria',\t'moore large ' : 'moore large',\t'moser ' : 'moser',\t'moto bike ' : 'moto bike',\t'motobecane ' : 'motobecane',\t'moulton ' : 'moulton',\t'move n smooth ' : 'move n smooth',\t'mtb ' : 'mtb',\t'muddy fox ' : 'muddy fox',\t'muddy foxtype ' : 'muddy fox',\t'muddyfox ' : 'muddy fox',\t'mycle ' : 'mycle',\t'myrider ' : 'myrider',\t'nan' : 'no match',\t'ncm ' : 'ncm',\t'neo ' : 'neo',\t'neowmouv ' : 'neowmouv',\t'new hudson ' : 'new hudson',\t'niner ' : 'niner',\t'ninertype ' : 'niner',\t'nirve ' : 'nirve',\t'no logo ' : 'no logo',\t'norco ' : 'norco',\t'nordest ' : 'nordest',\t'ns bikes ' : 'ns bikes',\t'nsu ' : 'nsu',\t'nuke proof ' : 'nuke proof',\t'nukeproof ' : 'nuke proof',\t'octane one ' : 'octane one',\t'odyssey ' : 'odyssey',\t'olympic ' : 'olympic',\t'omnium ' : 'omnium',\t'on one ' : 'on-one',\t'on-one ' : 'on-one',\t'on-onetype ' : 'on-one',\t'onone ' : 'onone',\t'onza ' : 'onza',\t'open ' : 'open',\t'opera ' : 'opera',\t'opollo ' : 'opollo',\t'optima ' : 'optima',\t'orange ' : 'orange',\t'orangecustom-built ' : 'orange',\t'orangeseatpost ' : 'orange',\t'orbea ' : 'orbea',\t'orbeatype ' : 'orbea',\t'orbit ' : 'orbit',\t'orbitatype ' : 'orbit',\t'orla kiely ' : 'orla kiely',\t'orro ' : 'orro',\t'orus ' : 'orus',\t'our generation ' : 'our generation',\t'ouxi ' : 'ouxi',\t'oxford bike works ' : 'oxford bike works',\t'oxylane ' : 'oxylane',\t'pace ' : 'pace',\t'panther ' : 'panther',\t'parlee ' : 'parlee',\t'pashley ' : 'pashley',\t'pashleytype ' : 'pashley',\t'pazzaz ' : 'pazzaz',\t'pearson ' : 'pearson',\t'pedal pals ' : 'pedal pals',\t'pelago ' : 'pelago',\t'pendelton ' : 'pendleton',\t'pendleton ' : 'pendleton',\t'pendletontype ' : 'pendleton',\t'peugeot ' : 'peugeot',\t'peugeotcustom-built ' : 'peugeot',\t'peugeottype ' : 'peugeot',\t'philips ' : 'philips',\t'pinacle ' : 'pinnacle',\t'pinarello ' : 'pinarello',\t'pinarellotype ' : 'pinarello',\t'pinerello ' : 'pinarello',\t'pinerello ' : 'pinarello',\t'pinnacle ' : 'pinnacle',\t'pinnacletype ' : 'pinnacle',\t'pinnacletype ' : 'pinnacle',\t'pinnaclr ' : 'pinnacle',\t'piranha ' : 'piranha',\t'pivot ' : 'pivot',\t'pivot cycles ' : 'pivot',\t'planet x ' : 'planet x',\t'planet xtype ' : 'planet x',\t'planetx ' : 'planet x',\t'pole ' : 'pole',\t'polygon ' : 'polygon',\t'polygontype ' : 'polygon',\t'powabyke ' : 'powabyke',\t'power patroltype ' : 'power patroltype',\t'power plus ' : 'power plus',\t'primo ' : 'primo',\t'pro-flex ' : 'proflex ',\t'pro-lite ' : 'prolite ',\t'probike ' : 'probike',\t'probikecustom-built ' : 'probike',\t'procycle ' : 'procycle',\t'professional ' : 'professional',\t'profile racing ' : 'profile racing',\t'proflex ' : 'proflex',\t'prolite ' : 'prolite ',\t'proteam ' : 'proteam',\t'puch ' : 'puch',\t'puky ' : 'puky',\t'punisher ' : 'punisher',\t'python ' : 'python',\t'quella ' : 'quella',\t'radford ' : 'radford',\t'ragley ' : 'ragley',\t'raleigh ' : 'raleigh',\t'raleighcustom-built ' : 'raleigh',\t'raleighnon-domestic product ' : 'raleigh',\t'raleightype ' : 'raleigh',\t'raliegh ' : 'raleigh',\t'rampage ' : 'rampage',\t'rayleigh ' : 'raleigh',\t'redemption ' : 'redemption',\t'reflex ' : 'reflex',\t'reflextype ' : 'reflex',\t'reilly ' : 'reilly',\t'revel bikes ' : 'revel bikes',\t'revolution ' : 'revolution',\t'reynolds ' : 'reynolds',\t'ribble ' : 'ribble',\t'ribbletype ' : 'ribble',\t'riddicktype ' : 'riddicktype',\t'ridgeback ' : 'ridgeback',\t'ridgebackcustom-built ' : 'ridgeback',\t'ridgebacktype ' : 'ridgeback',\t'ridgeyard ' : 'ridgeyard',\t'ridley ' : 'ridley',\t'ridleytype ' : 'ridley',\t'riese & m√ºller ' : 'riese & m√ºller',\t'ritchey ' : 'ritchey',\t'robin hood ' : 'robin hood',\t'rock rider ' : 'rockrider',\t'rocker' : 'rocker bmx',\t'rockrider' : 'rockrider',\t'rocky mountain ' : 'rocky mountain',\t'romet ' : 'romet',\t'rondo ' : 'rondo',\t'ronlap ' : 'ronlap',\t'roodog ' : 'roodog',\t'rooster ' : 'rooster',\t'rose ' : 'rose',\t'royal baby ' : 'royal baby',\t'rudge ' : 'rudge',\t'ruption ' : 'ruption',\t's and m bikes ' : 's and m bikes',\t's-works ' : 's-works',\t'salcano ' : 'salcano',\t'salsa ' : 'salsa',\t'samta cruz ' : 'santa cruz',\t'santa cruz ' : 'santa cruz',\t'santa cruztype ' : 'santa cruz',\t'santacruz ' : 'santa cruz',\t'santana ' : 'santana',\t'saracen ' : 'saracen',\t'saxon ' : 'saxon',\t'schindelhauer ' : 'schindelhauer',\t'schwinn ' : 'schwinn',\t'scoot ' : 'scott',\t'scot ' : 'scott',\t'scott ' : 'scott',\t'scottcustom-built ' : 'scott',\t'scotttype ' : 'scott',\t'se bikes ' : 'se bikes',\t'seasure ' : 'seasure',\t'sensa ' : 'sensa',\t'shockwave ' : 'shockwave',\t'shogun ' : 'shogun',\t'sickbikeco ' : 'sickbikeco',\t'silverfox ' : 'silverfox',\t'sinclair ' : 'sinclair',\t'smith & wesson ' : 'smith & wesson',\t'smyths ' : 'smyths',\t'smyths neon diva ' : 'smyths',\t'smyths toys ' : 'smyths',\t'snob ' : 'snob',\t'soka ' : 'soka',\t'sonder ' : 'sonder',\t'sparta ' : 'sparta',\t'specalized ' : 'specialized',\t'specialised ' : 'specialized',\t'specialized ' : 'specialized',\t'specializedcustom-built ' : 'specialized',\t'specializednon-domestic product ' : 'specialized',\t'specializedtype ' : 'specialized',\t'specilalized ' : 'specialized',\t'specilzed ' : 'specialized',\t'spiderman ' : 'spiderman',\t'spike ' : 'spike',\t'spookey joe ' : 'spookey joe',\t'sport mountain ' : 'sport mountain',\t'squish ' : 'squish',\t'squish - cannondale ' : 'squish',\t'squish (dawes) ' : 'squish',\t'sram ' : 'sram',\t'standard ' : 'standard',\t'standert ' : 'standert',\t'stanton ' : 'stanton',\t'star wars ' : 'star wars',\t'starley ' : 'starley',\t'state bicycle co. ' : 'state bicycle co.',\t'stealth bomber ' : 'stealth bomber',\t'storck ' : 'storck',\t'stowabike ' : 'stowabike',\t'strider ' : 'strider',\t'sun ' : 'sun',\t'surly ' : 'surly',\t'tall order ' : 'tall order',\t'taoci ' : 'taoci',\t'technogymtype ' : 'technogymtype',\t'temantype ' : 'temantype',\t'temple ' : 'temple',\t'temple cycles ' : 'temple',\t'temple cycles ' : 'temple',\t'tern ' : 'tern',\t'terrain ' : 'terrain',\t'terrano ' : 'terrano',\t'thorn ' : 'thorn',\t'tifosi ' : 'tifosi',\t'tiger ' : 'tiger',\t'time ' : 'time',\t'titus ' : 'titus',\t'tokyo ' : 'tokyo',\t'tokyo bike ' : 'tokyo',\t'tokyobike ' : 'tokyo',\t'townsend ' : 'townsend',\t'transition ' : 'transition',\t'trax ' : 'trax',\t'treck ' : 'trek',\t'trek ' : 'trek',\t'trek rail 5 ' : 'trek',\t'trek, ' : 'trek',\t'trekcustom-built ' : 'trek',\t'treks ' : 'trek',\t'trektype ' : 'trek',\t'trex ' : 'trek',\t'triban ' : 'triban',\t'triumph ' : 'triumph',\t'try bike ' : 'try bike',\t'trybike ' : 'try bike',\t'typhoon ' : 'typhoon',\t'ultegra ' : 'ultegra',\t'united ' : 'united',\t'univega ' : 'univega',\t'universal ' : 'universal',\t'universal hammerhead ' : 'universal hammerhead',\t'unknown ' : 'no match',\t'van moof ' : 'van moof',\t'van nicholasitem diameter ' : 'van nicholas',\t'van nicholastype ' : 'van nicholas',\t'vanmoof ' : 'vanmoof',\t'vanmooftype ' : 'vanmoof',\t'vela ' : 'vela',\t'veloretti ' : 'veloretti',\t'venom ' : 'venom',\t'ventum ' : 'ventum',\t'venturatype ' : 'venturatype',\t'verenti ' : 'verenti',\t'vertical ' : 'vertical',\t'vertigo ' : 'vertigo',\t'viking ' : 'viking',\t'viking belgravia ' : 'viking',\t'viking verona ' : 'viking',\t'viner ' : 'viner',\t'viscount ' : 'viscount',\t'visp racer ' : 'visp racer',\t'vittesse ' : 'vitesse',\t'vitus ' : 'vitus',\t'vitustype ' : 'vitus',\t'vivi ' : 'vivi',\t'vodo ' : 'voodoo',\t'vooddoo ' : 'voodoo',\t'voodo ' : 'voodoo',\t'voodo sobo ' : 'voodoo',\t'voodoo ' : 'voodoo',\t'voodoocustom-buit ' : 'voodoo',\t'voodootype ' : 'voodoo',\t'weeride ' : 'weeride',\t'wethepeople ' : 'wethepeople',\t'wheelie ' : 'wheelie',\t'whistle ' : 'whistle',\t'whites ' : 'whites',\t'whyte ' : 'whyte',\t'whyte bikes ' : 'whyte',\t'whyte rd-07 ' : 'whyte',\t'wiggins ' : 'wiggins',\t'wild ' : 'wild',\t'wild bikestype ' : 'wild bikestype',\t'wildcat ' : 'wildcat',\t'wildtrack ' : 'wildtrack',\t'wilier ' : 'wilier',\t'wilier triestina ' : 'wilier',\t'willier ' : 'wilier',\t'wishbone ' : 'wishbone',\t'wisper ' : 'wisper',\t'wolfbike ' : 'wolfbike',\t'x-rated ' : 'x-rated',\t'x-rated spine ' : 'x-rated',\t'xrated ' : 'x-rated',\t'xt18 ' : 'xt18',\t'yeti ' : 'yeti',\t'yeti cycles ' : 'yeti',\t'yt ' : 'yt',\t'yt industries ' : 'yt ',\t'yvolution ' : 'yvolution',\t'zinc ' : 'zinc',\t'zinctype ' : 'zinc',\t'zombie ' : 'zombie',\t'zoom ' : 'zoom',\t'zz no match ' : 'no match'}\n",
    "\n",
    "model_dict = {' rail ': ' rail', 'a line ': 'a line', 'a6 folding bike ': 'a6 folding bike', 'a7 link ': 'a7 link', 'absolute 1.1 disc ': 'absolute 1.1 disc', 'abyss ': 'abyss', 'access ': 'access', 'acid ': 'acid', 'adv 8.9e ': 'adv 8.9e', 'advanced pro 0 ': 'advanced pro 0', 'adventure ': 'adventure', 'adventure neo ': 'adventure neo', 'adventurer ': 'adventurer', 'aeris am9 ': 'aeris am9', 'aerium ': 'aerium', 'aero custom ': 'aero custom', 'aethos ': 'aethos', 'aftershock ': 'aftershock', 'aggresor ': 'aggresor', 'aggressor ': 'aggressor', 'agree ': 'agree', 'agressor 3.0 ': 'agressor 3.0', 'aim ': 'aim', 'aizan ': 'aizan', 'alibi ': 'alibi', 'alight ': 'alight', 'alight 2 city ': 'alight 2 city', 'allant ': 'allant', 'allez ': 'allez', 'alpha ': 'alpha', 'alpina ': 'alpina', 'alsina classic ': 'alsina classic', 'althea ': 'althea', 'altitude 970 ': 'altitude 970', 'aluminium hybrid ': 'aluminium hybrid', 'amr 5900 ': 'amr 5900', 'ams ': 'ams', 'analog ': 'analog', 'analog hardtail bike (2022) ': 'analog hardtail bike (2022)', 'anarchy 100 ': 'anarchy 100', 'anthem ': 'anthem', 'anyroad 2 ': 'anyroad 2', 'anytour ': 'anytour', 'aqua ': 'aqua', 'aquila ': 'aquila', 'arcade ': 'arcade', 'arcade 2011 ': 'arcade 2011', 'arcc e moulton ': 'arcc e moulton', 'areoad cf ': 'areoad cf', 'argon ': 'argon', 'ariel ': 'ariel', 'arkose ': 'arkose', 'ascender ': 'ascender', 'ash ': 'ash', 'aspect ': 'aspect', 'aspen ': 'aspen', 'aspero ': 'aspero', 'aspire ': 'aspire', 'atacama ': 'atacama', 'atb ': 'atb', 'athabasca ': 'athabasca', 'attain ': 'attain', 'attain gtc ': 'attain gtc', 'attention ': 'attention', 'av26mon ym ': 'av26mon ym', 'avail ': 'avail', 'avalanche ': 'avalanche', 'avanti 501 ': 'avanti 501', 'avertura2 6.7 ': 'avertura2 6.7', 'avro 1 2016 ': 'avro 1 2016', 'axial ': 'axial', 'axis ': 'axis', 'bad boy ': 'bad boy', 'badboy ': 'bad boy', 'bakka ': 'bakka', 'balance bike ': 'balance bike', 'banchee ': 'banshee', 'banshee ': 'banshee', 'bantu ': 'bantu', 'barracuda ': 'barracuda', 'basis ': 'basis', 'batman ': 'batman', 'bbl mtr 8.9m ': 'bbl mtr 8.9m', 'bbl mtx ': 'bbl mtx', 'bblt4manufacturer ': 'bblt4manufacturer', 'bear valley ': 'bear valley', 'beatnik 17 ': 'beatnik 17', 'beinn ': 'beinn', 'belgravia ': 'belgravia', 'belmont ': 'belmont', 'bergamont straitline ': 'bergamont straitline', 'beyond plus ': 'beyond plus', 'bienn ': 'beinn', 'big flyer 2021 ': 'big flyer 2021', 'big hit ': 'big hit', 'big sur disc ': 'big sur disc', 'bilango ': 'bilango', 'bisou ': 'bisou', 'bizango ': 'bizango', 'blackjack ': 'blackjack', 'blackstorm ': 'blackstorm', 'blast ': 'blast', 'bliss ': 'bliss', 'blossomby ': 'blossomby', 'bokeh ': 'bokeh', 'bomma 27.5 ': 'bomma 27.5', 'bonaly ': 'bonaly', 'boone ': 'boone', 'bordeaux ': 'bordeaux', 'borealis ': 'borealis', 'boss nut v2 ': 'boss nut v2', 'bossnut ': 'bossnut', 'britannia ': 'britannia', 'brom s6l 20 b-blk ': 'brom s6l 20 b-blk', 'bronson ': 'bronson', 'brownie ': 'brownie', 'bulls copperhead ': 'bulls copperhead', 'bulls wild cup 1 ': 'bulls wild cup 1', 'c 100 ': 'c 100', 'c line ': 'c line', 'c line electric ': 'c line electric', 'c line explore ': 'c line explore', 'c line urban ': 'c line urban', 'c line utility ': 'c line utility', 'c-line explore ': 'c-line explore', 'c-line m6l ': 'c-line m6l', 'c-type ': 'c-type', 'c100v2 mtb ': 'c100v2 mtb', 'c40 ': 'c40', 'caad ':'caad', 'caad 10 ': 'caad 10', 'caad 8 ': 'caad 8', 'caad optimo ': 'caad optimo', 'caad13 ': 'caad13', 'caadx ': 'caadx', 'caadx ultegra ': 'caadx ultegra', 'cafe ': 'cafe', 'caledonia 5 ': 'caledonia 5', 'cali ': 'cali', 'californium ': 'californium', 'camber ': 'camber', 'cambridge ': 'cambridge', 'camino ': 'camino', 'candice mixte ': 'candice mixte', 'canvas neo ': 'canvas neo', 'capra ': 'capra', 'carbon pro slr ': 'carbon pro slr', 'cargo hybrid ': 'cargo hybrid', 'carlina 480 wh ': 'carlina 480 wh', 'carnaby ': 'carnaby', 'carpe 15 ': 'carpe 15', 'carrero valour ': 'carrero valour', 'carve ': 'carve', 'casino xl ': 'casino xl', 'catherine 24 vb bike ': 'catherine 24 vb bike', 'centos 13 ': 'centos 13', 'cgr ': 'cgr', 'cgr ti ': 'cgr ti', 'challenge  ': 'challenge ', 'chaos ': 'chaos', 'chartres ': 'chartres', 'chas roberts ': 'chas roberts', 'checkpoint ': 'alr4', 'cherish ': 'cherish', 'chesterton ': 'chesterton', 'chinook ': 'chinook', 'city ': 'city', 'citypro e\\xadbike road bike ': 'citypro e\\xadbike road bike', 'civic (ladies’ step-through) ': 'civic (ladies’ step-through)', 'classic ': 'classic', 'claws ': 'claws', 'clencher ': 'clencher', 'clockwork ': 'clockwork', 'cmpt ': 'cmpt', 'cmt w al 5 21 m ye ': 'cmt w al 5 21 m ye', 'cnoc ': 'cnoc', 'cobalt ': 'cobalt', 'cobia ': 'cobia', 'colette ': 'colette', 'colnago v1r ': 'colnago v1r', 'colorade denver ': 'colorade denver', 'colt ': 'colt', 'commencal ramones ': 'commencal ramones', 'commuter 6 new ': 'commuter 6 new', 'comp ': 'comp', 'compact hybrid ': 'compact hybrid', 'compass folding bike ': 'compass folding bike', 'complete bike urban ': 'complete bike urban', 'connect ': 'connect', 'contend ': 'contend', 'contessa 26” ': 'contessa 26”', 'controller ': 'controller', 'cordonza ': 'cordonza', 'core 1.0 ': 'core 1.0', 'corsa ': 'corsa', 'cosmo ': 'cosmo', 'cosmos ': 'cosmos', 'cr1 ': 'cr1', 'cr1 comp ': 'cr1 comp', 'cr1 pro ': 'cr1 pro', 'creig 26 ': 'creig 26', 'criterium ': 'criterium', 'crixus cx 7005 t6 ': 'crixus cx 7005 t6', 'cross pro ': 'cross pro', 'cross race ': 'cross race', 'cross sport ': 'cross sport', 'crosscity ': 'crosscity', 'crosser ': 'crosser', 'crossfire ': 'crossfire', 'crosspath ': 'crosspath', 'crossroads ': 'crossroads', 'crosstrail ': 'crosstrail', 'crossway 20 hybrid ': 'crossway 20 hybrid', 'crossway urban 20 2020 m/l ': 'crossway urban 20 2020 m/l', 'crush ': 'crush', 'crx700 ': 'crx700', 'cs300 ': 'cs300', 'ct02manufacturer ': 'ct02manufacturer', 'ct62manufacturer ': 'ct62manufacturer', 'cubie 120 ': 'cubie 120', 'cubley ': 'cubley', 'cuda kinetic ': 'cuda kinetic', 'cujo ': 'cujo', 'cupcake ': 'cupcake', 'curbar 1 ': 'curbar 1', 'custom evil decals ': 'custom evil decals', 'custom fixed gear ': 'custom fixed gear', 'custom zr 9000 ': 'custom zr 9000', 'cyclocross 300 ': 'cyclocross 300', 'cyclon ': 'cyclon', 'd3 pro ': 'd3 pro', 'd31 ': 'd31', 'd4s  (folding) ': 'd4s  (folding)', 'd7 ': 'd7', 'dailytour ': 'dailytour', 'dakar a2 2018 ': 'dakar a2 2018', 'dakar gt ': 'dakar gt', 'dave ': 'dave', 'de novo ': 'de novo', 'defy ': 'defy', 'dekka ': 'dekka', 'demo ': 'demo', 'detonate ': 'detonate', 'detour ': 'detour', 'dew plus ': 'dew plus', 'dino lol ': 'dino lol', 'dinosaur ': 'dinosaur', 'discovery ': 'discovery', 'disney frozen ': 'disney frozen', 'diverge ': 'diverge', 'dogma ': 'dogma', 'dolce ': 'dolce', 'dolomite 4 ': 'dolomite 4', 'domane ': 'domane', 'drb freedom ': 'drb freedom', 'ds 2 ': 'ds 2', 'ds4 ': 'ds4', 'dual sport ': 'dual sport', 'duchess ': 'duchess', 'e-160 rs ': 'e-160 rs', 'e-bike ': 'e-bike', 'e-ebe-19-004-0001type ': 'e-ebe-19-004-0001type', 'e-horizon ': 'e-horizon', 'e-spillo classic ': 'e-spillo classic', 'e25 ': 'e25', 'ease e+ ': 'ease e+', 'ease-e ': 'ease-e', 'ebike ': 'ebike', 'ec 130e ': 'ec 130e', 'eclipse ': 'eclipse', 'edge 3.9 ': 'edge 3.9', 'edit ': 'edit', 'editor ': 'editor', 'electric bike (bosch) ': 'electric bike (bosch)', 'elegance ': 'elegance', 'elite ': 'elite', 'ella ': 'ella', 'ella hybrid ': 'ella hybrid', 'elops 3 ': 'elops 3', 'elyse ': 'elyse', 'emmelle panther ': 'emmelle panther', 'emonda ': 'emonda', 'endurance ': 'endurance', 'endure ': 'enduro', 'enduro ': 'enduro', 'entice ': 'entice', 'entity ': 'entity', 'entour ': 'entour', 'entourage ': 'entourage', 'ep-2 pro ': 'ep-2 pro', 'epic ': 'epic', 'equillibrium ': 'equillibrium', 'equinoxframe  ': 'equinoxframe ', 'equipe\\xa0 ': 'equipe\\xa0', 'escape ': 'escape', 'escarpe ': 'escarpe', 'etienne ': 'etienne', 'evade ': 'evade', 'everlast ': 'everlast', 'evian ': 'evian', 'evil ': 'evil', 'evo pro ': 'evo pro', 'evolution ': 'evolution', 'excelle ': 'excelle', 'exp 3.0 g20 lg ': 'exp 3.0 g20 lg', 'expedition ': 'expedition', 'experience ': 'experience', 'explore ': 'explore', 'explore e+ ': 'explore e+', 'explore e+2 ': 'explore e+', 'explosif ': 'explosif', 'f-si ': 'f-si', 'f29 ': 'f29', 'fade ': 'fade', 'fairfax sc 2 ': 'fairfax sc 2', 'falcon black diamond ': 'falcon black diamond', 'falcon turbine ': 'falcon turbine', 'fastrdad ': 'fastroad', 'fastroad ': 'fastroad', 'fastroad e ': 'fastroad e+', 'fastroad e+ ': 'fastroad e+', 'fathom ': 'fathom', 'fathom e+ ': 'fathom e+', 'faucet ': 'faucet', 'fcs.300 city sport ': 'fcs.300 city sport', 'feather ': 'feather', 'felt fr ': 'felt fr', 'felt q520 ': 'felt q520', 'fifth avenue ': 'fifth avenue', 'firechief ': 'firechief', 'firefox festival se ': 'firefox festival se', 'five ': 'five', 'flamingo 260 ': 'flamingo 260', 'flare ': 'flare', 'flit-16 ': 'flit-16', 'fluid ': 'fluid', 'fluid 7.1 (custom) ': 'fluid 7.1 (custom)', 'flyer ': 'flyer', 'flying circus ': 'flying circus', 'focus ': 'focus', 'fold hybrid ': 'fold hybrid', 'fondriest ': 'fondriest', 'four corners ': 'four corners', 'foxy ': 'foxy', 'fr frd ': 'fr frd', 'fratello ': 'fratello', 'freedom ': 'freedom', 'freespirit savage 20\" ': 'freespirit savage 20\"', 'freestyle 20\" ': 'freestyle 20\"', 'friday 27 fs 7 2020 ': 'friday 27 fs 7 2020', 'frog ': 'frog', 'frog 40 ': 'frog 40', 'frog 52 team sky ': 'frog 52 team sky', 'frog 55 ': 'frog 55', 'frog 62 ': 'frog 62', 'frog 69 ': 'frog 69', 'frozen ii ': 'frozen ii', 'fs team cb ': 'fs team cb', 'fs1 ': 'fs1', 'fuel ': 'fuel', 'fuji sportif ': 'fuji sportif', 'furnace ': 'furnace', 'fury ': 'fury', 'fuse 27.5+ 2021 hardtail mtb ': 'fuse 27.5+ 2021 hardtail mtb', 'fusion ': 'fusion', 'fx 1 ': 'fx 1', 'fx 2 ': 'fx 2', 'fx2 ': 'fx2', 'fx3 ': 'fx3', 'g-force ': 'g-force', 'galaxy ': 'galaxy', 'galibier ': 'galibier', 'gazelle miss grace ': 'gazelle miss grace', 'gazelle the heavy duty bike ': 'gazelle the heavy duty bike', 'gearsean ': 'gearsean', 'genesis day ': 'genesis day', 'genesis equilibrium 20 ': 'genesis equilibrium 20', 'genius lt 10 ': 'genius lt 10', 'gingersnap ': 'gingersnap', 'giro 300 ': 'giro 300', 'globe ': 'globe', 'go/bb001height ': 'go/bb001height', 'gold medal ': 'gold medal', 'goldrush ': 'goldrush', 'gradient ': 'gradient', 'grail 8 cf slx di2 ': 'grail 8 cf slx di2', 'grand prix ': 'grand prix', 'grater 5 ': 'grater 5', 'greenfield ': 'greenfield', 'grenoble ': 'grenoble', 'gridlock ': 'gridlock', 'gridlok ': 'gridlock', 'gryphin ': 'gryphin', 'gryphon ': 'gryphon', 'gsd ': 'gsd', 'gtr ': 'gtr', 'habit ': 'habit', 'habit neo ': 'habit neo', 'habit se ': 'habit se', 'hampton 19\" ': 'hampton 19\"', 'handbuilt ': 'handbuilt', 'hard rock ': 'hardrock', 'hardrock ': 'hardrock', 'harlem reflex ': 'harlem reflex', 'harmony ': 'harmony', 'harrier ': 'harrier', 'haste ': 'haste', 'hawk hill 2 ': 'hawk hill 2', 'hellcat ': 'hellcat', 'hightower ': 'hightower', 'holborn challange ': 'holborn challange', 'hoo koo e koo (hkek) ': 'hoo koo e koo (hkek)', 'hoodoo ': 'hoodoo', 'hooper pro 58 ': 'hooper pro 58', 'hot rock ': 'hotrock', 'hotrock ': 'hotrock', 'hotwalk ': 'hotwalk', 'htm 8.8 ': 'htm 8.8', 'hustle ': 'hustle', 'hyb 8.6 ': 'hyb 8.6', 'hyb 8.8 ': 'hyb 8.8', 'hyb 8.8 womens ': 'hyb 8.8 womens', 'hyb 8.9 ': 'hyb 8.9', 'hyb 8.9e ': 'hyb 8.9e', 'hyb 8.9e womens ': 'hyb 8.9e womens', 'hybrid comp w ': 'hybrid comp w', 'hybrid riverside 900 ': 'hybrid riverside 900', 'hybrid trail al ': 'hybrid trail al', 'hyde ': 'hyde', 'hype ': 'hype', 'iii ': 'iii', 'imp ': 'imp', 'impel ': 'impel', 'impulso ': 'impulso', 'inbred ': 'inbred', 'inflite ': 'inflite', 'initial ': 'initial', 'insomnia ': 'insomnia', 'intercity ': 'intercity', 'iroko ': 'iroko', 'islabike ': 'islabike', 'iso4202014 ': 'iso4202014', 'it 8  ': 'it 8 ', 'izip ': 'izip', 'jazzsx ': 'jazzsx', 'jeffsy - core 2 ': 'jeffsy - core 2', 'jekyll ': 'jekyll', 'jewel ': 'jewel', 'joe c27 ': 'joe c27', 'jr 6.1 ': 'jr 6.1', 'justice ': 'justice', 'k-star ': 'k-star', 'kaffenback ': 'kaffenback', 'kahuna ': 'kahuna', 'kalahari ': 'kalahari', 'kapur 1 ': 'kapur 1', 'karkinos ': 'karkinos', 'katana ': 'katana', 'kathamandu hybrid ': 'kathamandu hybrid', 'kathmandu ': 'kathmandu', 'kawasaki ': 'kawasaki', 'kenevo ': 'kenevo', 'kharma ': 'kharma', 'kinder ': 'kinder', 'king zydeco ': 'king zydeco', 'kingpin ': 'kingpin', 'komodo comp ': 'komodo comp', 'kraken ': 'kraken', 'krypton inte ': 'krypton inte', 'kula ': 'kula', 'kush ': 'kush', 'lana ': 'lana', 'langster 2011 ': 'langster 2011', 'lapierre ': 'lapierre', 'laterite ': 'laterite', 'lava ': 'lava', 'lavaro ': 'lavaro', 'le i ': 'le i', 'legend ': 'legend', 'levo turbo ': 'levo turbo', 'lexa ': 'lexa', 'lfh52spo ': 'lfh52spo', 'lifestyle lsr - 50 ': 'lifestyle lsr - 50', 'light 6 ': 'light 6', 'limba ': 'limba', 'link c7 ': 'link c7', 'litening ': 'litening', 'lithium ': 'lithium', 'lithium 1 ': 'lithium 1', 'lithium 2 ': 'lithium 2', 'lithium 3 ': 'lithium 3', 'lithium 3 w 16 ': 'lithium 3 w 16', 'lithium one ': 'lithium one', 'little big balance bike ': 'little big balance bike', 'liv ': 'liv', 'london road ': 'london road', 'lotto ': 'lotto', 'luna 20 ': 'luna 20', 'lux ': 'lux', 'lynskey viale ': 'lynskey viale', 'lynx ': 'lynx', 'm1438601 ': 'm1438601', 'm2l ': 'm2l', 'm3l ': 'm3l', 'm3o ': 'm3o', 'm3r ': 'm3r', 'm6l ': 'm6l', 'm6l (c-line explore) ': 'm6l (c-line explore)', 'm6l black edition ': 'm6l black edition', 'm6l titanium ': 'm6l titanium', 'm6lu raw ': 'm6lu raw', 'mach ': 'mach', 'madone ': 'madone', 'madonna ': 'madonna', 'madrid ': 'madrid', 'magma ': 'magma', 'majestic ': 'majestic', 'malt g2p tiagra ': 'malt g2p tiagra', 'mambo ': 'mambo', 'mantra ': 'mantra', 'marasa ': 'marasa', 'march ': 'march', 'marin alpine trail ': 'marin alpine trail', 'marin fairfax ': 'marin fairfax', 'marley 2.0 ': 'marley 2.0', 'marlin ': 'marlin', 'martin city ': 'martin city', 'matts j24 ': 'matts j24', 'mavaro ': 'mavaro', 'mavaro neo ': 'mavaro neo', 'maverick ': 'maverick', 'max ': 'max', 'maxi 2 ': 'maxi 2', 'medusa ': 'medusa', 'mega ': 'mega', 'megawatt 297 ': 'megawatt 297', 'melody ': 'melody', 'merida big trail 400 ': 'merida big trail 400', 'mesa gsd ': 'mesa gsd', 'mesh ': 'mesh', 'meteor ': 'meteor', 'metro ': 'metro', 'mhr 8.8 ': 'mhr 8.8', 'mht 8.6 ': 'mht 8.6', 'mht 8.6 womens ': 'mht 8.6 womens', 'mht 8.8 ': 'mht 8.8', 'mht 8.8 womens ': 'mht 8.8 womens', 'mht 8.9 ': 'mht 8.9', 'milk race special ': 'milk race special', 'mistral ': 'mistral', 'ml-009 ': 'ml-009', 'mobo ': 'mobo', 'mojo hd3 ': 'mojo hd3', 'molly ': 'molly', 'mono ': 'mono', 'monsal ': 'monsal', 'monzonite ': 'monzonite', 'moosher ': 'moosher', 'moterra ': 'moterra', 'moterra neo  ': 'moterra neo ', 'moterra neo lt ': 'moterra neo lt', 'motion ': 'motion', 'motus ': 'motus', 'motus tour ': 'motus tour', 'mt09 ': 'mt09', 'mt220 24f ': 'mt220 24f', 'mtb 2621 fs ': 'mtb 2621 fs', 'mtb1 ': 'mtb1', 'mtr 8.6 ': 'mtr 8.6', 'mtr 8.8 ': 'mtr 8.8', 'mtr 8.8 womens ': 'mtr 8.8 womens', 'mtr 8.9 ': 'mtr 8.9', 'mtr 9.0 ': 'mtr 9.0', 'mtx 8.6 ': 'mtx 8.6', 'mtx 8.6 blue m ': 'mtx 8.6 blue m', 'mtx 8.8 ': 'mtx 8.8', 'mtx 8.9 ': 'mtx 8.9', 'muirwoods ': 'muirwoods', 'multitrack ': 'multitrack', 'mx24 b ': 'mx24 b', 'mx24 team ': 'mx24 team', 'mx3 ': 'mx3', 'mx40 ': 'mx40', 'myka ': 'myka', 'myka ht pro ': 'myka ht pro', 'myt-26 ': 'myt-26', 'mythique ': 'mythique', 'n/a ': 'n/a', 'n7 fh 2020 ': 'n7 fh 2020', 'nakisi adventure bike ': 'nakisi adventure bike', 'nature ': 'nature', 'navigator ': 'navigator', 'nebula ': 'nebula', 'neon ': 'neon', 'nero ': 'nero', 'nerve al 9.0 sl ': 'nerve al 9.0 sl', 'ng 101 ': 'ng 101', 'nicasio ': 'nicasio', 'nitro 6.1 ': 'nitro 6.1', 'noah ': 'noah', 'nologo \"x\" ': 'nologo \"x\"', 'nomad ': 'nomad', 'noodle ': 'noodle', 'nucleus 275 vr 2021 ': 'nucleus 275 vr 2021', 'nuride hybrid ': 'nuride hybrid', 'nuroad ': 'nuroad', 'nzumbi ': 'nzumbi', 'nzumbi 26” ': 'nzumbi 26”', 'oakland ': 'oakland', 'occam h30 ': 'occam h30', 'octane one ': 'octane one', 'odessa ': 'odessa', 'odyssey ': 'odyssey', 'oiz ': 'oiz', 'old dutch ': 'old dutch', 'olive and orange ': 'olive and orange', 'omega ': 'omega', 'onna  ': 'onna ', 'optima hub ': 'optima hub', 'optimo ': 'optimo', 'original 500 ': 'original 500', 'ostro ': 'ostro', 'outrage ': 'outrage', 'outrider ': 'outrider', 'overload ': 'overload', 'p line electric ': 'p line electric', 'p4000 alu ': 'p4000 alu', 'p6l ': 'p6l', 'paddywagon ': 'paddywagon', 'pantera ': 'pantera', 'panther ': 'panther', 'paradox ': 'paradox', 'parkwood ': 'parkwood', 'parva ': 'parva', 'pashley ': 'pashley', 'patrol ': 'patrol', 'pavra ': ' parva', 'peak trail ': 'peak trail', 'peaktrail ': 'peak trail', 'peloton ': 'peloton', 'performance hybrid pro ': 'performance hybrid pro', 'perva ': ' parva', 'phantom ': 'phantom', 'phaze ': 'phaze', 'picador plus ': 'picador plus', 'pickenflick ': 'pickenflick', 'pioneer ': 'pioneer', 'pitch ': 'pitch', 'point ar ': 'point ar', 'pompino ': 'pompino', 'pop 16 ': 'pop 16', 'portobello ': 'portobello', 'powerfly fs4 eq ': 'powerfly fs4 eq', 'pre cursa ': 'pre cursa', 'preffisio ': 'preffisio', 'premiere ': 'premiere', 'prestige ': 'prestige', 'prima ': 'prima', 'primavera ': 'primavera', 'princess lillifee ': 'princess lillifee', 'prisidio 3 ': 'prisidio 3', 'pro carbon ': 'pro carbon', 'pro series 20.5 ': 'pro series 20.5', 'probike, city discovery ': 'probike, city discovery', 'procaliber ': 'procaliber', 'process 153 ': 'process 153', 'professional ': 'professional', 'profile mini ': 'profile mini', 'propel ': 'propel', 'puch ': 'puch', 'purgatory ': 'purgatory', 'push bicycle ': 'push bicycle', 'quick ': 'quick', 'quick neo ': 'quick neo', 'r872 ': 'r872', 'race ': 'race', 'racelight ': 'racelight', 'racer ': 'racer', 'rad power cargo ': 'rad power cargo', 'radar ': 'radar', 'raider ': 'raider', 'rallon ': 'rallon', 'ramones 24 ': 'ramones 24', 'ransom ': 'ransom', 'rascal ': 'rascal', 'raw laquer ': 'raw laquer', 'razor vrl 2015 ': 'razor vrl 2015', 'razorback ': 'razorback', 'rc 120 ': 'rc 120', 'rc 520 gravel ': 'rc 520 gravel', 'rc120 ': 'rc120', 'rc500 ': 'rc500', 'reaction ': 'reaction', 'reaction hybrid ': 'reaction hybrid', 'reactor 290 ': 'reactor 290', 'recoil ': 'recoil', 'recon ': 'recon', 'record ': 'record', 'red feather ': 'red feather', 'reflex ': 'reflex', 'reign ': 'reign', 'remedy ': 'remedy', 'revel ': 'revel', 'revole e+ ': 'revole e+', 'revolt ': 'revolt', 'rincon ': 'rincon', 'riprock ': 'riprock', 'ris ': 'ris', 'riverside ': 'riverside', 'riviera ': 'riviera', 'rlds02 ': 'rlds02', 'rlx ': 'rlx', 'road e+ ': 'road e+', 'roam ': 'roam', 'robinson ': 'robinson', 'rock ': 'rock', 'rock hopper ': 'rockhopper', 'rock rider ': 'rockrider', 'rock se ': 'rock se', 'rockadile ': 'rockadile', 'rockfall ': 'rockfall', 'rockhopper ': 'rockhopper', 'rockrider ': 'rockrider', 'rocky mountain ': 'rocky mountain', 'rohloff tour, disk ': 'rohloff tour, disk', 'roma l 3 ': 'roma l 3', 'roscoe ': 'roscoe', 'rothan ': 'rothan', 'roubaix ': 'roubaix', 'roubion ': 'roubion', 'rouen 650 ': 'rouen 650', 'route 66 ': 'route 66', 'routier ': 'routier', 'rove al ': 'rove al', 'royal ': 'royal', 'royale 2021 ': 'royale 2021', 'rs 120l ': 'rs 120l', 'rt-58 ': 'rt-58', 'rt57 2014 ': 'rt57 2014', 'rt58 ': 'rt58', 'rtd90 ': 'rtd90', 'rubato ': 'rubato', 'ruby ': 'ruby', 'ruby expert ': 'ruby expert', 's duro ': 's duro', 's-pedelec ': 's-pedelec', 's-works ': 's-works', 's10 ': 's10', 's2 ': 's2', 's2l ': 's2l', 's3l ': 's3l', 's6l ': 's6l', 'salcata ': 'salcata', 'san anselemo ds1 ': 'san anselemo ds1', 'san quentin ': 'san quentin', 'sanction elite ': 'sanction elite', 'santiago ': 'santiago', 'saracen dtox ': 'saracen dtox', 'sardinha 2 ': 'sardinha 2', 'saruna ': 'saruna', 'sb5 turq ': 'sb5 turq', 'sc700 ': 'sc700', 'scale ': 'scale', 'scale 960 ': 'scale 960', 'scalpel ': 'scalpel', 'scalpel ht ': 'scalpel ht', 'scalpel se ': 'scalpel se', 'scalpel-si ': 'scalpel-si', 'scarlet ': 'scarlet', 'scr 3.0 ': 'scr 3.0', 'sduro cross 3.0 ': 'sduro cross 3.0', 'se fat quad ': 'se fat quad', 'secteur ': 'secteur', 'seek2 ': 'seek2', 'semper ': 'semper', 'series 1 ': 'series 1', 'serloin 3 ': 'serloin 3', 'session 9 xo1 ': 'session 9 xo1', 'shimano positron ': 'shimano positron', 'shizuoka ': 'shizuoka', 'shoreditch ': 'shoreditch', 'sight ': 'sight', 'silex 300 ': 'silex 300', 'single speed ': 'single speed', 'sirius ': 'sirrus', 'sirrus ': 'sirrus', 'sirus ': 'sirrus', 'skye ': 'skye', 'sl cross ': 'sl cross', 'sl road ': 'sl road', 'slalom ': 'slalom', 'slammer ': 'slammer', 'slamr ': 'slammer', 'slant ': 'slant', 'slash ': 'slash', 'slr 8.6 ': 'slr 8.6', 'slr 8.8 ': 'slr 8.8', 'slr 8.9 ': 'slr 8.9', 'slr 8.9 carbon ': 'slr 8.9 carbon', 'slr 8.9 disc ': 'slr 8.9 disc', 'slr 9.4 carbon ': 'slr 9.4 carbon', 'slr 9.6 carbon ': 'slr 9.6 carbon', 'smlro c6 ': 'smlro c6', 'smoke ': 'smoke', 'solace 25 ': 'solace 25', 'solaris ': 'solaris', 'somerby ': 'somerby', 'soul 26 ': 'soul 26', 'spark ': 'spark', 'spectral cf 7 ': 'spectral cf 7', 'spectre ': 'spectre', 'speed ': 'speed', 'speed 900 ': 'speed 900', 'speedster ': 'speedster', 'spike ': 'spike', 'spiral ': 'spiral', 'spirit x9 ': 'spirit x9', 'sportif ': 'sportif', 'sports disk l ': 'sports disk l', 'sportster ': 'sportster', 'squish ': 'squish', 'sr suntour ': 'sr suntour', 'sr suntour nex ': 'sr suntour nex', 'st120 ': 'st120', 'stance ': 'stance', 'stanton sherpa ': 'stanton sherpa', 'starlight ': 'starlight', 'status ': 'status', 'stc gold ': 'stc gold', 'stealth ': 'stealth', 'steppenwolf tiago ': 'steppenwolf tiago', 'stereo ': 'stereo', 'stereo hybrid ': 'stereo hybrid', 'sting hybrid 120 hpc sl ': 'sting hybrid 120 hpc sl', 'stingray ': 'stingray', 'stomper ace ': 'stomper ace', 'stomper ace 2020 ': 'stomper ace 2020', 'storm 7.1 14 ': 'storm 7.1 14', 'storm 7.4 ': 'storm 7.4', 'strada 2 ': 'strada 2', 'strada 3 ': 'strada 3', 'stratos ': 'stratos', 'stump jumper ': 'stump jumper', 'stumpjumper ': 'stumpjumper', 'sub cross 20 men small ': 'sub cross 20 men small', 'sub tour step through ': 'sub tour step through', 'subway ': 'subway', 'sulcata ': 'sulcata', 'super v1000 ': 'super v1000', 'superbike ': 'superbike', 'superlight pro ': 'superlight pro', 'supersix ': 'supersix', 'supersix evo ': 'supersix evo', 'supersix evo cx ': 'supersix evo cx', 'supersix evo neo ': 'supersix evo neo', 'supersix evo se ': 'supersix evo se', 'superx  ': 'superx ', 'supreme hybrid ': 'supreme hybrid', 'sutra ': 'sutra', 'swift ': 'swift', 'switch 6 ': 'switch 6', 'sx250 ': 'sx250', 'synapse ': 'synapse', 'synapse carbon ': 'synapse carbon', 'synapse carbon flat bar ': 'synapse carbon flat bar', 'synapse neo ': 'synapse neo', 'synapse sora female ': 'synapse sora female', 'sync 3.0 ': 'sync 3.0', 'synergy ': 'synergy', 'systemsix  ': 'systemsix ', 't130 scr ': 't130 scr', 't4 max ': 't4 max', 'tadpole mini ': 'tadpole mini', 'taival ': 'taival', 'talas 1.0 ': 'talas 1.0', 'talera ': 'talera', 'talon ': 'talon', 'talon e+ ': 'talon e+', 'talus 2 ': 'talus 2', 'tango ': 'tango', 'tarmac ': 'tarmac', 'tcr ': 'tcr', 'tcx ': 'tcx', 'tdf ': 'tdf', 'tdf ltd ': 'tdf ltd', 'tdf road ': 'tdf road', 'team ': 'team', 'team sky road 67 ': 'team sky road 67', 'tekarra ': 'tekarra', 'teman ': 'teman', 'tempest ': 'tempest', 'teocali ': 'teocali', 'terrago ': 'terrago', 'terrain 1 ': 'terrain 1', 'tesoro neo ': 'tesoro neo', 'tfs 24 ': 'tfs 24', 'thorn sherpa ': 'thorn sherpa', 'thrive ': 'thrive', 'throughroad ': 'throughroad', 'tiger vintage ': 'tiger vintage', 'tilt 900 ': 'tilt 900', 'titan ': 'titan', 'titanio art decor ': 'titanio art decor', 'titanium firenze ': 'titanium firenze', 'tm02 ': 'tm02', 'tnt-5 ': 'tnt-5', 'tony doyle ': 'tony doyle', 'top fuel ': 'top fuel', 'top fuel 8 2020 ': 'top fuel 8 2020', 'topstone ': 'topstone', 'topstone alloy  ': 'topstone alloy ', 'topstone carbon ': 'topstone carbon', 'topstone neo ': 'topstone neo', 'torino sr4 ': 'torino sr4', 'toughroad slr 1 ': 'toughroad slr 1', 'toughroad slr 2 (2020) ': 'toughroad slr 2 (2020)', 'touring ': 'touring', 'touring hybrid ': 'touring hybrid', 'touring hybrid pro 500 ': 'touring hybrid pro 500', 'touriste ': 'touriste', 'tourmalet ': 'tourmalet', 'town bike ': 'town bike', 'toy story 4 ': 'toy story 4', 'trace ': 'trace', 'track ': 'track', 'track classic ': 'track classic', 'trackbike ': 'trackbike', 'trail ': 'trail', 'trail 4 ': 'trail 4', 'trail 5 ': 'trail 5', 'trail 6 ': 'trail 6', 'trail 7 ': 'trail 7', 'trail 7 29er (2020) ': 'trail 7 29er (2020)', 'trail 8 29er ': 'trail 8 29er', 'trail neo  ': 'trail neo ', 'trail neo 3 ': 'trail neo 3', 'traker ': 'traker', 'trance ': 'trance', 'trance 3 ': 'trance 3', 'trance e+ ': 'trance e+', 'transistion ': 'transistion', 'transit ': 'transit', 'travel ': 'travel', 'travel pro ': 'travel pro', 'treadwell ': 'treadwell', 'treadwell neo ': 'treadwell neo', 'trekker ': 'trekker', 'trekking ': 'trekking', 'triban ': 'triban', 'tricriss ': 'tricriss', 'tricycle ': 'tricycle', 'trike concept ': 'trike concept', 'trinity ': 'trinity', 'tripster atr ': 'tripster atr', 'ts-wwhzby-519 ': 'ts-wwhzby-519', 'ts-wwhzby-521 ': 'ts-wwhzby-521', 'tsr ': 'tsr', 'tt team ': 'tt team', 'tues ': 'tues', 'tufftrax ': 'tufftrax', 'turbo 12 ': 'turbo 12', 'turbo creo comp e5 ': 'turbo creo comp e5', 'turbo levo ': 'turbo levo', 'turbo levo fsr fattie ': 'turbo levo fsr fattie', 'turbo levo s2 alloy ': 'turbo levo s2 alloy', 'turbo levo sl comp ': 'turbo levo sl comp', 'turbo tero eq ': 'turbo tero eq', 'turbo vado 3.0 ': 'turbo vado 3.0', 'turbo valdo v4 ': 'turbo valdo v4', 'twilight ': 'twilight', 'two ': 'two', 'two two ': 'two two', 'ultimate  ': 'ultimate ', 'ultimate cf sl ': 'ultimate cf sl', 'ultimate cf slx ': 'ultimate cf slx', 'unsure ': 'unsure', 'urb 8.6 ': 'urb 8.6', 'urb 8.9 ': 'urb 8.9', 'urban 8.8 ': 'urban 8.8', 'urban a1 ': 'urban a1', 'usps ': 'usps', 'utah ': 'utah', 'v1 classic ': 'v1 classic', 'valour ': 'valour', 'vandal ': 'vandal', 'vanmoof s3 ': 'vanmoof s3', 'vanquish ': 'vanquish', 'vanteo ': 'vanteo', 'vektar\\xa0 ': 'vektar\\xa0', 'vendetta ': 'vendetta', 'vengance ': 'vengance', 'venge ': 'venge', 'vengeance ': 'vengeance', 'vengeance e ': 'vengeance e', 'ventoux ': 'ventoux', 'ventum gs1 ': 'ventum gs1', 'ventura ': 'ventura', 'venum mamba ': 'venum mamba', 'verve ': 'verve', 'via nirone ': 'via nirone', 'vibe h30 ': 'vibe h30', 'vice ': 'vice', 'vienna ': 'vienna', 'vigorelli ': 'vigorelli', 'viking ': 'viking', 'villain ': 'villain', 'virtue city ': 'virtue city', 'virtuoso ': 'virtuoso', 'vita ': 'vita', 'vitesse ': 'vitesse', 'vivid ': 'vivid', 'volare ': 'volare', 'vortice ': 'vortice', 'vr3w ': 'vr3w', 'vulcan ': 'vulcan', 'vybe d7 ': 'vybe d7', 'walbrook ': 'walbrook', 'warbird ': 'warbird', 'wasp ': 'wasp', 'wethepeople  - arcade ': 'wethepeople  - arcade', 'whitechapel ': 'whitechapel', 'wilhelm xviii ': 'wilhelm xviii', 'winster ': 'winster', 'x barbour ': 'x barbour', 'x cal 8 29er ': 'x cal 8 29er', 'x caliber ': 'x caliber', 'x road 2 ': 'x road 2', 'x trance ': 'x trance', 'x-bow ': 'x-bow', 'x-caliber ': 'x-caliber', 'x-calibre 9 ': 'x-calibre 9', 'x-rated shockwave ': 'x-rated shockwave', 'x/city ': 'x/city', 'x2 ': 'x2', 'x3 ': 'x3', 'x7 sport ': 'x7 sport', 'xc ': 'xc', 'xc 26 ': 'xc 26', 'xc26 ': 'xc26', 'xcaliber ': 'xcaliber', 'xcaliber 9 ': 'xcaliber 9', 'xce28 ': 'xce28', 'xms 120 ': 'xms 120', 'xr3 ': 'xr3', 'xrr1 ': 'xrr1', 'xtc jnr ': 'xtc jnr', 'xtrada 6 ': 'xtrada 6', 'xyc ': 'xyc', 'zaskar ': 'zaskar', 'zelos ': 'zelos', 'zest 26 ': 'zest 26', 'zing deluxe ': 'zing deluxe', 'zircus ': 'zircus', 'zlz electric ': 'zlz electric', 'zobop  ': 'zobop ', 'zombie ': 'zombie', 'zz no match ': 'no match'} \n",
    "colour_dict_2 = {'aqua' : 'blue', \t'beige' : 'beige', \t'black' : 'black', \t'blue' : 'blue', \t'bronze' : 'bronze', \t'brown' : 'brown', \t'burgundy' : 'burgundy', \t'celest' : 'celeste', \t'celeste' : 'celeste', \t'charcoal' : 'grey', \t'chrome' : 'chrome', \t'cream' : 'cream', \t'emerald' : 'green', \t'gold' : 'gold', \t'graphite' : 'grey', \t'gray' : 'grey', \t'green' : 'green', \t'grey' : 'grey', \t'gun metal' : 'grey', \t'gunmetal' : 'grey', \t'iridescent' : 'iridescent', \t'ivory' : 'white', \t'lilac' : 'lilac', \t'magenta' : 'purple', \t'mint' : 'green', \t'multicolour' : 'multicolour', \t'mustard' : 'yellow', \t'navy' : 'blue', \t'olive' : 'green', \t'orange' : 'orange', \t'pink' : 'pink', \t'purple' : 'purple', \t'rainbow' : 'multicolour', \t'red' : 'red', \t'sand' : 'sand', \t'silver' : 'silver', \t'sliver' : 'silver', \t'teal' : 'blue', \t'turquoise' : 'blue', \t'white':'white',\t'yellow':'yellow'}\n",
    "type_dict = {'adult' : 'adult', \t'balance' : 'balance', \t'bmx' : 'bmx', \t'bmx ' : 'bmx ', \t'cargo' : 'cargo', \t'commuter ' : 'commuter ', \t'cross ' : 'cross ', \t'cruiser' : 'cruiser', \t'cyclocross' : 'cyclocross', \t'dirt jumper' : 'dirt jumper', \t'downhill' : 'downhill', \t'dutch ' : 'dutch ', \t'fixed' : 'single speed', \t'fixie' : 'single speed', \t'folding ' : 'folding ', \t'gravel' : 'gravel', \t'hardtail' : 'hardtail', \t'hybrid' : 'hybrid', \t'kids' : 'kids', \t'mountain' : 'mountain', \t'mtb' : 'mtb', \t'race ' : 'race ', \t'racer' : 'racer', \t'racing' : 'racing', \t'road' : 'road', \t'single speed' : 'single speed', \t'tandem' : 'tandem', \t'time trial' : 'time trial', \t'touring' : 'touring', \t'track' : 'track', \t'trail' : 'trail', \t'trial' : 'trial', \t'triathlon' : 'triathlon', \t'tricycle' : 'tricycle', \t'tt ' : 'tt ', \t'unicycle' : 'unicycle', \t'vintage' : 'vintage', 'zz no match ': 'no match'}\n",
    "gender_dict = {'boys' : 'boys', \t'female' : 'ladies', \t'girls' : 'girls', \t'ladies' : 'ladies', \t'lady' : 'ladies', \t'men' : 'mens', \t'mens' : 'mens', \t'unisex' : 'unisex', \t'women' : 'ladies', 'zz no match ': 'no match'}\n",
    "wheel_dict = {'24 ' : '24\"', \t'24in' : '24\"', \t'24\"' : '24\"', \t'26 ' : '26\"', \t'26in' : '26\"', \t'26\"' : '26\"', \t'27 ' : '27\"', \t'27in' : '27\"', \t'27\"' : '27\"', \t'27.5 ' : '27.5\"', \t'27.5\"' : '27.5\"', \t'27.5in' : '27.5in', \t'28 ' : '28\"', \t'28in' : '28\"', \t'28\"' : '28\"', \t'29 ' : '29\"', \t'29in' : '29\"', \t'29\"' : '29\"', \t'29er' : '29\"', \t'650 ' : '650b', \t'650b' : '650b', \t'700 ' : '700c', \t'700c' : '700c', \t'700x' : '700c', 'zz no match ': 'no match'}\n",
    "electric_dict = {'e-bike' : 'e-bike', \t'e-horizon' : 'e-bike', \t'e-mini' : 'e-bike', \t'e-mountain' : 'e-bike', \t'e-shimano' : 'e-bike', \t'e-st' : 'e-bike', \t'e-st' : 'e-bike', \t'e+ ' : 'e-bike', \t'e+1' : 'e-bike', \t'e+2' : 'e-bike', \t'ebike' : 'e-bike', \t'electric' : 'e-bike', \t'hyb 8.9e' : 'e-bike', \t'hyb 8.9e womens' : 'e-bike', \t'adventure neo' : 'e-bike', \t'canvas neo' : 'e-bike', \t'habit neo' : 'e-bike', \t'mavaro neo' : 'e-bike', \t'moterra neo ' : 'e-bike', \t'moterra neo lt' : 'e-bike', \t'quick neo' : 'e-bike', \t'tesoro neo' : 'e-bike', \t'trail neo ' : 'e-bike', \t'treadwell neo' : 'e-bike', \t'crosscity' : 'e-bike', \t'crossfuse' : 'e-bike', \t'impel' : 'e-bike', \t'vengeance e' : 'e-bike', \t'x/city' : 'e-bike', \t'compact hybrid' : 'e-bike', \t'ella hybrid' : 'e-bike', \t'fold hybrid' : 'e-bike', \t'kathamandu hybrid' : 'e-bike', \t'nuride hybrid' : 'e-bike', \t'reaction hybrid' : 'e-bike', \t's-pedelec' : 'e-bike', \t'stereo hybrid' : 'e-bike', \t'supreme hybrid' : 'e-bike', \t'touring hybrid' : 'e-bike', \t'anytour' : 'e-bike', \t'dailytour' : 'e-bike', \t'ease e+' : 'e-bike', \t'entour' : 'e-bike', \t'explore e+' : 'e-bike', \t'explore e+2' : 'e-bike', \t'fastroad e+' : 'e-bike', \t'fathom e+' : 'e-bike', \t'revole e+' : 'e-bike', \t'road e+' : 'e-bike', \t'talon e+' : 'e-bike', \t'trance e+' : 'e-bike', 'zz no match ': 'no match'}\n",
    "year_dict = {'2000 ' : '2000 ', \t'2001 ' : '2001 ', \t'2002 ' : '2002 ', \t'2003 ' : '2003 ', \t'2004 ' : '2004 ', \t'2005 ' : '2005 ', \t'2006 ' : '2006 ', \t'2007 ' : '2007 ', \t'2008 ' : '2008 ', \t'2009 ' : '2009 ', \t'2010 ' : '2010 ', \t'2011 ' : '2011 ', \t'2012 ' : '2012 ', \t'2013 ' : '2013 ', \t'2014 ' : '2014 ', \t'2015 ' : '2015 ', \t'2016 ' : '2016 ', \t'2017 ' : '2017 ', \t'2018 ' : '2018 ', \t'2019 ' : '2019 ', \t'2020 ' : '2020 ', \t'2021 ' : '2021 ', \t'2022 ' : '2022 ', 'zz no match ': 'no match'}\n",
    "groupset_dict = {'105 ' : 'shimano ','campag ' : 'campagnolo', \t'athena' : 'campagnolo ', \t'campagnolo ' : 'campagnolo ', \t'chorus' : 'campagnolo ', \t'di2 ' : 'shimano ', \t'dura ace' : 'shimano ', \t'record' : 'campagnolo ', \t'shimano ' : 'shimano ', \t'sram ' : 'sram ', \t'suntour ' : 'suntour ', \t'suntour ' : 'suntour ', \t'ultegra ' : 'shimano ','zz no match ': 'no match'}\n",
    "material_dict = {'aluminium ' : 'aluminium ', \t'carbon ' : 'carbon ', \t'steel ' : 'steel ', \t'titanium' : 'titanium', 'zz no match ': 'no match'}\n",
    "brakes_dict = {'caliper' : 'caliper', \t'disc' : 'disc', \t'disk' : 'disc', \t'rim' : 'rim', \t'v-brake' : 'v-brake', \t'v-brake' : 'v-brake', \t'v-type' : 'v-brake', 'zz no match ': 'no match'}\n",
    "size_dict = {'43cm' : 'x small', \t'43 cm' : 'x small', \t'43 ' : 'x small', \t'44cm' : 'x small', \t'44 cm' : 'x small', \t'44 ' : 'x small', \t'45cm' : 'x small', \t'45 cm' : 'x small', \t'45 ' : 'x small', \t'46cm' : 'x small', \t'46 cm' : 'x small', \t'46 ' : 'x small', \t'47cm' : 'small', \t'47 cm' : 'small', \t'47 ' : 'small', \t'48cm' : 'small', \t'48 cm' : 'small', \t'48 ' : 'small', \t'49cm' : 'small', \t'49 cm' : 'small', \t'49 ' : 'small', \t'50cm' : 'small', \t'50 cm' : 'small', \t'50 ' : 'small', \t'51cm' : 'small', \t'51 cm' : 'small', \t'51 ' : 'small', \t'52cm' : 'small', \t'52 cm' : 'small', \t'52 ' : 'small', \t'53cm' : 'medium', \t'53 cm' : 'medium', \t'53 ' : 'medium', \t'54cm' : 'medium', \t'54 cm' : 'medium', \t'54 ' : 'medium', \t'55cm' : 'medium', \t'55 cm' : 'medium', \t'55 ' : 'medium', \t'56cm' : 'medium', \t'56 cm' : 'medium', \t'56 ' : 'medium', \t'57cm' : 'large', \t'57 cm' : 'large', \t'57 ' : 'large', \t'58cm' : 'large', \t'58 cm' : 'large', \t'58 ' : 'large', \t'59cm' : 'large', \t'59 cm' : 'large', \t'59 ' : 'large', \t'60cm' : 'large', \t'60 cm' : 'large', \t'60 ' : 'large', \t'61cm' : 'large', \t'61 cm' : 'large', \t'61 ' : 'large', \t'62cm' : 'x large', \t'62 cm' : 'x large', \t'62 ' : 'x large', \t'63cm' : 'x large', \t'63 cm' : 'x large', \t'63 ' : 'x large', \t'64cm' : 'x large', \t'64 cm' : 'x large', \t'64 ' : 'x large', \t'65cm' : 'x large', \t'65 cm' : 'x large', \t'65 ' : 'x large', \t'66cm' : 'x large', \t'66 cm' : 'x large', \t'66 ' : 'x large', \t'x small' : 'x small', \t'small' : 'small', \t'medium' : 'medium', \t'large' : 'large', \t'x large' : 'x large', \t'extra large' : 'x large', \t'xl ' : 'x large', \t'xxl ' : 'x large', \t'xx large' : 'x large', 'zz no match ': 'no match'}\n",
    "other_terms_dict = {'401' : '401', \t' 6 ' : ' 6 ', \t' 8 ' : ' 8 ', \t' e ' : ' e ', \t' l ' : ' l ', \t' se ' : ' se ', \t' sl ' : ' sl ', \t' sr ' : ' sr ', \t' st ' : ' st ', \t' x ' : ' x ', \t' xl ' : ' xl ', \t' yt  ' : ' yt  ', \t'100 ' : '100 ', \t'1000 ' : '1000 ', \t'101 ' : '101 ', \t'120 ' : '120 ', \t'15.5\" ' : '15.5\" ', \t'153 ' : '153 ', \t'160 ' : '160 ', \t'1800 ' : '1800 ', \t'20 ' : '20 ', \t'20\" ' : '20\" ', \t'21 ' : '21 ', \t'27.5+ ' : '27.5+ ', \t'275 ' : '275 ', \t'297 ' : '297 ', \t'3-speed ' : '3-speed ', \t'300 ' : '300 ', \t'330 ' : '330 ', \t'3500 ' : '3500 ', \t'400 ' : '400 ', \t'429 ' : '429 ', \t'457 ' : '457 ', \t'480 ' : '480 ', \t'50 ' : '50 ', \t'500 ' : '500 ', \t'5000 ' : '5000 ', \t'520 ' : '520 ', \t'525 ' : '525 ', \t'530 ' : '530 ', \t'653 ' : '653 ', \t'705 ' : '705 ', \t'765 ' : '765 ', \t'8.8 ' : '8.8 ', \t'802 ' : '802 ', \t'900 ' : '900 ', \t'901 ' : '901 ', \t'920 ' : '920 ', \t'960 ' : '960 ', \t'b75 ' : 'b75 ', \t'bosch ' : 'bosch ', \t'c-line ' : 'c-line ', \t'c-type ' : 'c-type ', \t'c100 ' : 'c100 ', \t'city ' : 'city ', \t'comp  ' : 'comp  ', \t'compact ' : 'compact ', \t'copper ' : 'copper ', \t'custom ' : 'custom ', \t'd2 ' : 'd2 ', \t'd3 ' : 'd3 ', \t'd4s ' : 'd4s ', \t'dark ' : 'dark ', \t'decathlon ' : 'decathlon ', \t'ds ' : 'ds ', \t'ds4 ' : 'ds4 ', \t'dsc1 ' : 'dsc1 ', \t'dual ' : 'dual ', \t'duro ' : 'duro ', \t'dxt500 ' : 'dxt500 ', \t'e-160' : 'e-160', \t'e25' : 'e25', \t'e5 ' : 'e5 ', \t'ep-2' : 'ep-2', \t'eq ' : 'eq ', \t'ex ' : 'ex ', \t'ex5' : 'ex5', \t'ex8' : 'ex8', \t'f85' : 'f85', \t'factory' : 'factory', \t'fs4' : 'fs4', \t'fsr' : 'fsr', \t'fx ' : 'fx ', \t'fx1' : 'fx1', \t'fx2' : 'fx2', \t'fx3' : 'fx3', \t'gsd' : 'gsd', \t'h-3m30' : 'h-3m30', \t'h30' : 'h30', \t'h6r' : 'h6r', \t'halford' : 'halford', \t'light' : 'light', \t'limited' : 'limited', \t'ltd' : 'ltd', \t'mtx' : 'mtx', \t'neon' : 'neon', \t'plus' : 'plus', \t'prix' : 'prix', \t'pro' : 'pro', \t'quick' : 'quick', \t'r3000' : 'r3000', \t'r872' : 'r872', \t'rc ' : 'rc ', \t'rc120' : 'rc120', \t'rc500' : 'rc500', \t'replica' : 'replica', \t'rs' : 'rs', \t'rt58' : 'rt58', \t's10' : 's10', \t's2' : 's2', \t's2l' : 's2l', \t's3l' : 's3l', \t's6l' : 's6l', \t'sand' : 'sand', \t'sc700' : 'sc700', \t'slc ' : 'slc ', \t'slr ' : 'slr ', \t'slx ' : 'slx ', \t'sport ' : 'sport ', \t'sr4 ' : 'sr4 ', \t'st120 ' : 'st120 ', \t'st530 ' : 'st530 ', \t'st540 ' : 'st540 ', \t'super ' : 'super ', \t'suspension ' : 'suspension ', \t'sx250 ' : 'sx250 ', \t'synapse ' : 'synapse ', \t'tcx ' : 'tcx ', \t'tdf ' : 'tdf ', \t'tm1+ ' : 'tm1+ ', \t'tnt-5 ' : 'tnt-5 ', \t'turbo ' : 'turbo ', \t'v2 ' : 'v2 ', \t'v3 ' : 'v3 ', \t'v4 ' : 'v4 ', \t'vr ' : 'vr ', \t'vr3w ' : 'vr3w ', \t'vrl ' : 'vrl ', \t'w3 ' : 'w3 ', \t'x2 ' : 'x2 ', \t'x3 ' : 'x3 ', \t'xc ' : 'xc ', \t'xc ' : 'xc ', \t'xc.26 ' : 'xc.26 ', \t'xc26 ' : 'xc26 ', 'zz no match ': 'no match'}\n",
    "common_terms = ['ns ','orange ','cross ', 'no logo '] #these are often returned incorrectly so filtered out and used as a last resort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cbd8b3",
   "metadata": {},
   "source": [
    "# DEFINING FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d60a3",
   "metadata": {},
   "source": [
    "## index_url_list_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd0b813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_url_list_fn(url,pages):\n",
    "    global index_url_list\n",
    "    index_url_list = []\n",
    "    \n",
    "    if run == 'ebay':\n",
    "        url = 'https://www.ebay.co.uk/sch/i.html?_from=R40&_nkw=bicycle&_sacat=0&Department=Unisex%2520Adults%7CMen%7CWomen&_dcat=177831&rt=nc&LH_ItemCondition=1500%7C2500%7C3000%7C7000&_ipg=240'\n",
    "        index_url_list.append(url)  #adds the first URL (with no pagination)\n",
    "        for i in range (2,pages):\n",
    "            i_as_string = str(i)  #Note that to concatenate all elements need to be strings\n",
    "            index_url_list.append(url+'&_pgn='+i_as_string)\n",
    "            i=i+1\n",
    "        return index_url_list\n",
    "    \n",
    "    elif run == 'gumtree':\n",
    "        url = 'https://www.gumtree.com/search?search_category=bicycles&search_location=uk&q=bicycle'\n",
    "        index_url_list.append(url)  #adds the first URL (with no pagination)\n",
    "        for i in range (2,pages):\n",
    "            i_as_string = str(i)  #Note that to concatenate all elements need to be strings\n",
    "            index_url_list.append(url+'&page='+i_as_string)\n",
    "            i=i+1\n",
    "        return index_url_list\n",
    "\n",
    "    elif run =='sbike':\n",
    "        url = 'https://stolen-bikes.co.uk/stolen-bikes/'\n",
    "        index_url_list.append(url)  #adds the first URL (with no pagination)\n",
    "        for i in range (2,pages):\n",
    "            i_as_string = str(i)  #Note that to concatenate all elements need to be strings\n",
    "            index_url_list.append(url+'page/'+i_as_string)\n",
    "            i=i+1\n",
    "        return index_url_list   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9208817",
   "metadata": {},
   "source": [
    "## all_detail_urls_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d88449ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_detail_urls_fn (index_url_list):\n",
    "    \n",
    "    global all_detail_urls\n",
    "    all_detail_urls = []\n",
    "    t = 1\n",
    "    \n",
    "    for url in index_url_list:\n",
    "        get_detail_url_fn(url)\n",
    "        if run == 'gumtree':\n",
    "            print ('Getting detail URLs from ',t,'of', len(index_url_list),'index pages. Total URLs:',len(detail_urls))\n",
    "            time.sleep(random.randint(120,180))\n",
    "            t = t+1\n",
    "            \n",
    "        all_detail_urls.extend(detail_urls)\n",
    "        print ('length of all_detail_urls is:', len(all_detail_urls))\n",
    "\n",
    "#    print (len(all_detail_urls), run, 'URLs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08f141",
   "metadata": {},
   "source": [
    "## get_detail_url_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a81640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detail_url_fn(url):\n",
    "    global detail_urls\n",
    "    detail_urls = []\n",
    "\n",
    "    if run == 'ebay':  \n",
    "        response = requests.get(url)\n",
    "        if not response.ok:\n",
    "            print('server responded:', response.status_code)\n",
    "        else:\n",
    "            index_soup = BeautifulSoup(response.text, 'html') \n",
    "        try:\n",
    "            links = index_soup.find_all('a', class_='s-item__link')\n",
    "        except:\n",
    "            links = []\n",
    "        detail_urls = [item.get('href') for item in links]\n",
    "        for i in range (0,len(detail_urls)):\n",
    "            ebay_ID = detail_urls[i].split('?')\n",
    "            detail_urls[i] = ebay_ID[0]\n",
    "           \n",
    "    elif run == 'gumtree':\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')    \n",
    "        try:\n",
    "            links = soup.find_all('a', class_='listing-link')\n",
    "        except:\n",
    "            links = []\n",
    "        detail_urls = []\n",
    "        detail_urls = ['https://www.gumtree.com'+item.get('href') for item in links]   \n",
    " \n",
    "    elif run == 'sbike':\n",
    "        response = requests.get(url)\n",
    "        if not response.ok:\n",
    "            print('server responded:', response.status_code)\n",
    "        else:\n",
    "            index_soup = BeautifulSoup(response.text, 'html')\n",
    "        try:\n",
    "            links = index_soup.find_all('div', class_='col-md-12 whitebox listblock stolenbike')\n",
    "        except:\n",
    "            links = []     \n",
    "        for link in links:\n",
    "            detail_url = link.find('a')['href']\n",
    "            detail_urls.append(detail_url)\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f459fa7",
   "metadata": {},
   "source": [
    "## ID_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc7b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ID_fn (xls_ID, all_detail_urls):\n",
    "\n",
    "    global ID_df\n",
    "    ID_df = pd.read_excel(xls_ID)\n",
    "    today = datetime.today()\n",
    "    ID_df[today] = \"\"\n",
    "\n",
    "    new_urls = 0\n",
    "    \n",
    "    print ('all_detail_urls length:',len(all_detail_urls))\n",
    "    known_IDs = 0\n",
    "    \n",
    "    for ID in all_detail_urls:\n",
    "        if ID in ID_df['page_url'].unique():\n",
    "            row = ID_df[ID_df['page_url']==ID].index.values #this is the row where the ID appears\n",
    "            ID_df.loc[row,today] = '1'\n",
    "            known_IDs = known_IDs + 1\n",
    "    \n",
    "        else:\n",
    "            new_row_df = pd.DataFrame({'page_url':[ID], today:[1]})\n",
    "            ID_df = pd.concat([ID_df, new_row_df], ignore_index = True,)\n",
    "            ##\n",
    "            #print('ID_df length is:',len(ID_df))\n",
    "            ##\n",
    "            new_urls = new_urls+1  #this just counts how many new urls there are today\n",
    "\n",
    "    ID_df=ID_df.dropna(axis = 0, how = 'all') # drop rowns that are completely null\n",
    "    ID_df = ID_df.reset_index(drop=True) # re-index to keep everything nice and neat\n",
    "\n",
    "    print ('Total number of IDs looks at: ',len(all_detail_urls))\n",
    "    print ('Total number of NEW IDs: ',new_urls)\n",
    "    print ('Total number of known_IDs', known_IDs)\n",
    "    print ('Length of ID_df',len(ID_df))\n",
    "#    print ('Total number of IDs stored:', len(ID_df))\n",
    "\n",
    "    #xls_ID = '/Users/neil.collard/Documents/Curious_Projects/Untheft/test/fake_IDs.xlsx'\n",
    "    ID_df.to_excel(xls_ID, index = False)\n",
    "    \n",
    "#    print(run, 'IDs updated with new updates')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ad192",
   "metadata": {},
   "source": [
    "## urls_to_get_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22cafe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def urls_to_get_fn (ID_df):\n",
    "    print ('getting details for', run)\n",
    "    global target_IDs\n",
    "    target_IDs = []\n",
    "    print ('Target_ID length before is',len(target_IDs))\n",
    "    for i in range (len(ID_df)):\n",
    "        if ID_df.loc[i,'details_captured'] != 1:\n",
    "            target_IDs.append(ID_df.loc[i,'page_url'])\n",
    "    print ('Target_ID length after is',len(target_IDs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e42b6e",
   "metadata": {},
   "source": [
    "## get_detail_soup_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72833d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detail_soup_fn(url):\n",
    "     \n",
    "    response = requests.get(url)  \n",
    "    if not response.ok:\n",
    "        print('server responded:', response.status_code)\n",
    "    else:\n",
    "        global product_soup\n",
    "        product_soup = BeautifulSoup(response.text, 'html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936358b",
   "metadata": {},
   "source": [
    "## ebay_detail_getter_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed12398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebay_detail_getter_fn(product_soup):\n",
    "\n",
    "#Title\n",
    "    global title\n",
    "    title = []\n",
    "    try:\n",
    "        title = product_soup.find('h1', class_='x-item-title__mainTitle').find('span').text\n",
    "    except: ' '\n",
    "#Price    \n",
    "    global price\n",
    "    price = []\n",
    "    try:\n",
    "        price = product_soup.find('span', id='prcIsum').get('content')\n",
    "    except:\n",
    "        try:\n",
    "            price = product_soup.find('span', id='mm-saleDscPrc').get('content')\n",
    "        except:\n",
    "            try:\n",
    "                price = product_soup.find('span', id='prcIsum_bidPrice').get('content')\n",
    "            except:\n",
    "                try:\n",
    "                    price = product_soup.find('span', class_='s-item__price').get('content')\n",
    "                except: ' ' \n",
    "#Seller    \n",
    "    global seller\n",
    "    seller = []\n",
    "    try:\n",
    "        seller_r = product_soup.find('div', class_='ux-seller-section__item--seller').text\n",
    "        seller = seller_r.split(' ')[0]\n",
    "    except: ' ' \n",
    "#Product ID    \n",
    "    global product_ID\n",
    "    try:\n",
    "        product_ID = each_url.split('itm/')\n",
    "        product_ID = product_ID[1]\n",
    "    except: ' '        \n",
    "#condition   \n",
    "    global product_details\n",
    "    global details_dict\n",
    "    global keys\n",
    "    global values\n",
    "    try:\n",
    "        product_details = product_soup.find('div', class_='vim x-about-this-item').get_text()\n",
    "#        print ('\\n',product_ID)\n",
    "#        print (product_details)\n",
    "    except: ' ' \n",
    "    try:\n",
    "        categories = {\"condition is:\":\"%%condition is:\",\"Title:\" : \"%%Title:\", \"Price:\" : \"%%Price:\", \"Seller id:\" : \"%%Seller id:\",\"Condition:\" : \"%%Condition:\", \"Brand:\" : \"%%Brand:\", \"Bike Type:\" : \"%%Bike Type:\", \"Frame Size:\" : \"%%Frame Size:\", \"Wheel Size:\" : \"%%Wheel Size:\", \"Department:\" : \"%%Department:\", \"Suspension Type:\" : \"%%Suspension Type:\", \"Material:\" : \"%%Material:\", \"Colour:\" : \"%%Colour:\", \"Model:\" : \"%%Model:\", \"Brake Type:\" : \"%%Brake Type:\", \"Number of Speeds:\" : \"%%Number of Speeds:\", \"Handlebar Type:\" : \"%%Handlebar Type:\", \"Gear Change Mechanism:\" : \"%%Gear Change Mechanism:\", \"  Type:\" : \"%%  Type:\", \"Shifter Style:\" : \"%%Shifter Style:\", \"MPN:\" : \"%%MPN:\", \"Frame Number:\" : \"%%Frame Number:\", \"Features:\" : \"%%Features:\", \"Model Year:\" : \"%%Model Year:\", \"Vintage:\" : \"%%Vintage:\", \"Custom built:\" : \"%%Custom built:\"}\n",
    "        keys = list(categories.keys())\n",
    "        values = list(categories.values())\n",
    "        for i in range (1,len(categories)):\n",
    "            product_details = product_details.replace(keys[i],values[i])\n",
    "\n",
    "        product_details = product_details.split('%%')\n",
    "        for i in range (1,len(product_details)):\n",
    "            product_details[i] = product_details[i].split(':')\n",
    "        details_dict = {product_details[i][0]:product_details[i][1] for i in range (0,len(product_details))} \n",
    "    except: ' '\n",
    " #location\n",
    "    global location\n",
    "    location = []\n",
    "    try: \n",
    "        location = product_soup.find('span', class_=\"ux-textspans ux-textspans--BOLD ux-textspans--SECONDARY\").get_text()    \n",
    "    except: ' '\n",
    "#updated     \n",
    "    global updated\n",
    "    updated = []\n",
    "    global revision_history   \n",
    "    try:\n",
    "        updated = product_soup.find('div', class_=\"vi-desc-revHistory\").get_text()\n",
    "        print (updated)\n",
    "    except: 'nothing here'\n",
    "#image url\n",
    "    global image_stuff\n",
    "    global image_url\n",
    "    global picture_count       \n",
    "    try:\n",
    "        image_stuff = product_soup.find('button', class_=\"ux-image-filmstrip-carousel-item active image\")\n",
    "        image_stuff = str(image_stuff)\n",
    "        image_stuff = image_stuff.split('\" src=\"')\n",
    "        image_url = image_stuff[1]\n",
    "        image_url = image_url.replace('s-l64.jpg\"/></button>','s-l1200.jpg')\n",
    "        picture_count = image_stuff[0]\n",
    "        picture_count = picture_count.split('Picture 1 of ')\n",
    "        picture_count = picture_count[1]\n",
    "        picture_count = picture_count.split('\"')\n",
    "        picture_count = picture_count[0]       \n",
    "    except:\n",
    "        image_stuff = []\n",
    "        image_url = []\n",
    "        picture_count = []\n",
    "#Revision History\n",
    "    first_update = []    \n",
    "# create the revision history url from a stem and the product ID   \n",
    "    revision_history_url = ('https://www.ebay.co.uk/rvh/'+str(product_ID))\n",
    "    response = requests.get(revision_history_url)\n",
    "    if not response.ok:\n",
    "        print('server responded:', response.status_code)\n",
    "    else:\n",
    "        revision_history_soup = BeautifulSoup(response.text, 'html') \n",
    "    try:\n",
    "        first_update = revision_history_soup.find(class_=\"vi-columnClass\").text\n",
    "    except: ' '\n",
    "#writes everything to a dictionary called data\n",
    "#this uses the details_dict dictionary to extract the values for specific categories\n",
    "    global data\n",
    "    data = {\n",
    "        'title_orig': title,\n",
    "        'price': price,\n",
    "        'seller': seller,\n",
    "        'ebay_ID': product_ID,\n",
    "        'image url': image_url,\n",
    "        'picture_count':picture_count,\n",
    "        'location': location,\n",
    "        'condition': details_dict.get('Condition'),\n",
    "        'make_orig': details_dict.get('Brand'),\n",
    "        'type_orig': details_dict.get('Bike Type'),\n",
    "        'size_orig': details_dict.get('Frame Size'),\n",
    "        'Wheel Size': details_dict.get('Wheel Size'),\n",
    "        'Department': details_dict.get('Department'),\n",
    "        'Suspension Type': details_dict.get('Suspension Type'),\n",
    "        'Material': details_dict.get('Material'),\n",
    "        'colour_orig': details_dict.get('Colour'),\n",
    "        'model_orig': details_dict.get('Model'),\n",
    "        'Brake Type': details_dict.get('Brake Type'),\n",
    "        'Number of Speeds': details_dict.get('Number of Speeds'),\n",
    "        'Handlebar Type': details_dict.get('Handlebar Type'),\n",
    "        'Gear Change Mechanism': details_dict.get('Gear Change Mechanism'),\n",
    "        'type_orig': details_dict.get('Type'),\n",
    "        'Shifter Style': details_dict.get('Shifter Style'),\n",
    "        'MPN': details_dict.get('MPN'),\n",
    "        'framenumber': details_dict.get('Frame Number'),\n",
    "        'Features': details_dict.get('Features'),\n",
    "        'year_orig': details_dict.get('Model Year'),\n",
    "        'Vintage': details_dict.get('Vintage'),   \n",
    "        'page_url': each_url,\n",
    "        'date_reported': today\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14feba30",
   "metadata": {},
   "source": [
    "## gumtree_detail_getter_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5563fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumtree_detail_getter_fn(product_soup):\n",
    "#Title\n",
    "    global title\n",
    "    title = []\n",
    "    try:\n",
    "        title = product_soup.find('h1', class_='css-4rz76v e1pt9h6u6').text      \n",
    "    except: 'title fail'\n",
    "#Price\n",
    "    global price\n",
    "    price = []\n",
    "    try:\n",
    "        price = product_soup.find('h3', itemprop = 'price').get('content')\n",
    "    except: 'price fail'\n",
    "#Location\n",
    "    global location\n",
    "    location = []\n",
    "    try:\n",
    "        location = product_soup.find('h4', itemprop = 'addressLocality').text\n",
    "    except: 'location fail'       \n",
    "#pictures    \n",
    "    global pictures\n",
    "    pictures = []\n",
    "    try:\n",
    "        pictures = product_soup.find('p', class_ = 'carousel-counter').text\n",
    "        #splits out the total number of pictures (9) from the '1 of 9' string\n",
    "        try:\n",
    "            pictures = pictures.split() [2]\n",
    "        except: ' '\n",
    "    except: 'pictures fail'  \n",
    "#image url\n",
    "#confession time - I could not perfect the scrapping so spend a lot of time messing with the output to get the results that I am after\n",
    "    global image_stuff\n",
    "    global image_url      \n",
    "    try:\n",
    "        image_stuff = product_soup.find('div', class_=\"image-carousel carousel cms-carousel\")\n",
    "        image_stuff = str(image_stuff)\n",
    "        image_stuff = image_stuff.split(' src=\"')\n",
    "        image_url = image_stuff[1]\n",
    "        image_url = image_url.split('\"/><div class=\"')\n",
    "        image_url = image_url[0]     \n",
    "    except:\n",
    "        image_stuff = ['']\n",
    "        image_url = ['']    \n",
    "#seller\n",
    "    global seller\n",
    "    seller = []\n",
    "    try:\n",
    "        seller = product_soup.find('div', class_='css-16tsqsb e4jfc8t14')\n",
    "        seller = seller.find('a')['href']\n",
    "        seller = 'https://gumtree.com'+str(seller)\n",
    "    except: 'seller fail' \n",
    "#seller_stats\n",
    "    global seller_stats\n",
    "    seller_stats = [] \n",
    "    try:\n",
    "        seller_stats = product_soup.find('p', class_ = 'seller-stats-text').text\n",
    "    except: 'seller _stats fail'\n",
    "#description\n",
    "    global description\n",
    "    description = []\n",
    "    try:\n",
    "        description = product_soup.find('p', itemprop = 'description').text\n",
    "    except: 'description fail'   \n",
    "#ad_ID\n",
    "    global ad_id\n",
    "    ad_id = []\n",
    "    try:\n",
    "        ad_id = product_soup.find('b', itemprop = 'sku').text\n",
    "    except: 'ad_id fail'    \n",
    "    global data\n",
    "    data = {\n",
    "        'make_orig': title,\n",
    "        'price': price,\n",
    "        'location': location,\n",
    "        'picture_count': pictures,\n",
    "        'image url': image_url,\n",
    "        'seller': seller,\n",
    "        'seller_history': seller_stats,\n",
    "        'description': description,\n",
    "        'ebay_ID': ad_id,\n",
    "        'page_url': each_url,\n",
    "        'date_reported': today\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9c6cd",
   "metadata": {},
   "source": [
    "## sbike_detail_getter_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99d86a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbike_detail_getter_fn(product_soup):\n",
    "    today = datetime.today()\n",
    "#Title\n",
    "    try:\n",
    "        header = product_soup.find('div', class_='col-md-12 et_pb_slide_description simpletitle').text\n",
    "        header = header.split('\\n')\n",
    "        title = header[1].replace('Stolen ','')\n",
    "        location = header[3]\n",
    "        date = header [4]\n",
    "        reward = header [5]\n",
    "    \n",
    "    except: 'title fail'\n",
    "#description\n",
    "    try:\n",
    "        description = product_soup.find('div', class_ = 'bikedescription').text\n",
    "        #removing the guff at the beginning of the string\n",
    "        description = description.replace('\\nBike Description\\n                            ','')\n",
    "    except: 'description fail'   \n",
    "#colour\n",
    "#basically pulling out everything with a 'p' tag and then assigning the first element to colour\n",
    "    all_p_tags = []\n",
    "    for p_tag in product_soup.find_all(\"p\"): \n",
    "        all_p_tags.append(p_tag.get_text())\n",
    "        colour = all_p_tags[0]\n",
    "    global data\n",
    "    data = {\n",
    "        'make_orig': title,\n",
    "        'location': location,\n",
    "        'date_from_sbike': date,\n",
    "        'reward': reward,      \n",
    "        'colour_orig': colour,\n",
    "        'description': description,\n",
    "        'page_url': each_url,\n",
    "        'date_reported':today\n",
    "    }\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5c240",
   "metadata": {},
   "source": [
    "## write_data_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f44a549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_fn(data):\n",
    "    global raw_df\n",
    "    data_df = pd.DataFrame([data])\n",
    "    raw_df = pd.concat([raw_df, data_df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3312ff46",
   "metadata": {},
   "source": [
    "## update ID function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "098bd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ID (status):\n",
    "    xls_ID = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/' + run + '_IDs.xlsx'    \n",
    "    if status == 'success':\n",
    "        print (status)\n",
    "        completed_detail = pd.read_excel(xls_ID)\n",
    "\n",
    "        for ID in target_IDs:\n",
    "            row = completed_detail[completed_detail['page_url']==ID].index.values\n",
    "            row = row[0]\n",
    "            completed_detail.loc[row,'details_captured']=1\n",
    "\n",
    "        completed_detail.to_excel(xls_ID, index = False)\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        print (\"completed ID's updated for \\n \",xls_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d1880",
   "metadata": {},
   "source": [
    "## log_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cd81bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_fn(run):\n",
    "    xls_log = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/' + run + '_log.xlsx'\n",
    "    log_df = pd.read_excel(xls_log)\n",
    "\n",
    "    end_time = datetime.today()\n",
    "    open_count = log_df.iloc[-1,2]\n",
    "    close_count = len(ID_df)\n",
    "    new_additions = close_count - open_count\n",
    "    fresh_additions = len(target_IDs)\n",
    "    last_run = log_df.iloc[-1,0]\n",
    "    elapsed_time = end_time - last_run\n",
    "    delta_time = elapsed_time / pd.Timedelta(minutes=1)\n",
    "    if  fresh_additions < 1600:\n",
    "        records_per_hour = (new_additions / delta_time)*60\n",
    "        records_per_day = records_per_hour * 24\n",
    "    elif new_additions == fresh_additions:\n",
    "        records_per_hour = 'null'\n",
    "        records_per_day = 'null'\n",
    "    \n",
    "    new_log = pd.DataFrame({\n",
    "        \"Time / Date of run\" : [end_time],\n",
    "        \"opening count\" : [open_count],\n",
    "        \"closing count\" : [close_count],\n",
    "        \"new additions\" : [new_additions],\n",
    "        \"fresh new additions\" : [fresh_additions],\n",
    "        \"Time / Date of last run\" : [last_run],\n",
    "        \"Elapsed Time (mins)\" : [int(delta_time)],\n",
    "        \"records added per hour\" : [records_per_hour],\n",
    "        \"records added per day\" : [records_per_day]})\n",
    "\n",
    "\n",
    "    log_df = pd.concat([log_df, new_log], ignore_index = True,)\n",
    "    log_df.to_excel(xls_log, index = False)\n",
    "    print ('New row added to existing ',run,'log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194afc1",
   "metadata": {},
   "source": [
    "# MODEL PARSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dcbe2d",
   "metadata": {},
   "source": [
    "# load_data_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f0c3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_fn(run):\n",
    "    global ebay_df\n",
    "    global gumtree_df\n",
    "    global bikereg_df\n",
    "    global sbike_df\n",
    "    \n",
    "    if run == 'listed':\n",
    "        ebay_xls = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/ebay_raw.xlsx'\n",
    "        ebay_df = pd.read_excel(ebay_xls)\n",
    "        ebay_df.replace(np.nan, '' , inplace = True)\n",
    "        ebay_opening_len = len(ebay_df)        \n",
    "        print ('ebay is:', ebay_opening_len,'records')        \n",
    "        gumtree_xls = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/gumtree_raw.xlsx'\n",
    "        gumtree_df = pd.read_excel(gumtree_xls)\n",
    "        gumtree_df.replace(np.nan, '' , inplace = True)\n",
    "        gumtree_opening_len = len(gumtree_df)\n",
    "        print ('gumtree is:', gumtree_opening_len,'records')  \n",
    "    \n",
    "    elif run =='stolen':\n",
    "        bikereg_xls = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/bikereg_raw.xlsx'\n",
    "        bikereg_df = pd.read_excel(bikereg_xls)\n",
    "        bikereg_df.replace(np.nan, '' , inplace = True)\n",
    "        bikereg_opening_len = len(bikereg_df)\n",
    "        print ('bikereg (Bike Register) is:', bikereg_opening_len,'records')\n",
    "        \n",
    "        sbike_xls = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/sbike_raw.xlsx'\n",
    "        sbike_df = pd.read_excel(sbike_xls)\n",
    "        sbike_df.replace(np.nan, '' , inplace = True)\n",
    "        sbike_opening_len = len(sbike_df)\n",
    "        print ('sbike (Stolen Bike .co.uk) is:', sbike_opening_len,'records')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a4d14b",
   "metadata": {},
   "source": [
    "##  prepare_df_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f813d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df_fn(run):\n",
    "    global ebay_df\n",
    "    global gumtree_df\n",
    "    global bikereg_df\n",
    "    global sbike_df\n",
    "    \n",
    "    if run == 'listed':\n",
    "        for i in range (len(ebay_df)):\n",
    "            ebay_df.loc[i,'concatination'] = str(ebay_df.loc[i,'title_orig']) + ' ' + str(ebay_df.loc[i,'make_orig']) + ' ' + str(ebay_df.loc[i,'model_orig']) +' ' + str(ebay_df.loc[i,'type_orig']) +' '  + str(ebay_df.loc[i,'colour_orig']) +' '+ str(ebay_df.loc[i,'year_orig']) +' '+ str(ebay_df.loc[i,'Wheel Size']) +' '+ str(ebay_df.loc[i,'Department']) +' '+ str(ebay_df.loc[i,'Material']) +' '+ str(ebay_df.loc[i,'Brake Type']) +' '+ str(ebay_df.loc[i,'size_orig']) +' '\n",
    "        for i in range (len(gumtree_df)):\n",
    "            gumtree_df.loc[i,'concatination'] = str(gumtree_df.loc[i,'title_orig']) + ' ' + str(gumtree_df.loc[i,'description']) + ' '  \n",
    "    \n",
    "    elif run =='stolen':\n",
    "        for i in range (len(bikereg_df)):\n",
    "            bikereg_df.loc[i,'concatination'] = str(bikereg_df.loc[i,'make_orig']) + ' ' + str(bikereg_df.loc[i,'model_orig']) + ' ' + str(bikereg_df.loc[i,'Type_orig']) +' ' + str(bikereg_df.loc[i,'colour_orig']) +' '\n",
    "        for i in range (len(sbike_df)):\n",
    "            sbike_df.loc[i,'concatination'] = str(sbike_df.loc[i,'title_orig']) + ' ' + str(sbike_df.loc[i,'colour_orig']) + ' ' + str(sbike_df.loc[i,'description']) +' ' \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de5dcd1",
   "metadata": {},
   "source": [
    "## identify_IDs_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c126506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_IDs_fn(run):\n",
    "    global ebay_df\n",
    "    global gumtree_df\n",
    "    global bikereg_df\n",
    "    global sbike_df\n",
    "    \n",
    "    if run == 'listed':\n",
    "        ebay_opening_len = len(ebay_df)\n",
    "        gumtree_opening_len = len(gumtree_df)\n",
    "        \n",
    "#ebay\n",
    "        ebay_df.reset_index(inplace = True)    \n",
    "        ebay_df = ebay_df.drop('level_0', axis=1)\n",
    "        ebay_ID_xls = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/ebay_IDs.xlsx'\n",
    "        ebay_ID_df = pd.read_excel(ebay_ID_xls)\n",
    "        print('Ebay_IDs opened successfully - length =:', len(ebay_ID_df))\n",
    "\n",
    "        y = 0\n",
    "        z = 0\n",
    "        for i in range (len(ebay_df)):\n",
    "            y = y+1\n",
    "            if y > len(ebay_df)/10:\n",
    "                #print (i,' records complete')\n",
    "                y = 0 \n",
    "            url = ebay_df.loc[i,'page_url']\n",
    "            if (ebay_ID_df['page_url'].eq(url)).any():\n",
    "                a = np.where(ebay_ID_df['page_url'].values == url)\n",
    "                a = list(a)\n",
    "                a = a[0][0]      \n",
    "                a = int(a)\n",
    "                if ebay_ID_df.loc[a,'cleaned'] == 1:\n",
    "                    ebay_df.loc[i,'page_url'] = 'to_delete'\n",
    "                elif ebay_ID_df.loc[a,'cleaned'] != 1:\n",
    "                    ebay_ID_df.loc[a,'cleaned'] = 1\n",
    "        print ('before delation', len(ebay_df))\n",
    "        for i in range (len(ebay_df)):\n",
    "            if ebay_df.loc[i,'page_url'] == 'to_delete':\n",
    "                ebay_df = ebay_df.drop(i)\n",
    "        print ('after delation', len(ebay_df))\n",
    "        ebay_ID_df.to_excel(ebay_ID_xls, index = False)   \n",
    "\n",
    "\n",
    "#gumtree           \n",
    "        gumtree_df.reset_index(inplace = True)\n",
    "        gumtree_df = gumtree_df.drop('level_0', axis=1)           \n",
    "        gumtree_ID_xls = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/gumtree_IDs.xlsx'\n",
    "        gumtree_ID_df = pd.read_excel(gumtree_ID_xls)\n",
    "        print('Gumtree_IDs opened successfully - length =:', len(gumtree_ID_df))\n",
    "\n",
    "        y = 0\n",
    "        z = 0\n",
    "        for i in range (len(gumtree_df)):\n",
    "            y = y+1\n",
    "            if y > len(gumtree_df)/10:\n",
    "                #print (i,' records complete')\n",
    "                y = 0 \n",
    "            url = gumtree_df.loc[i,'page_url']\n",
    "            if (gumtree_ID_df['page_url'].eq(url)).any():\n",
    "                a = np.where(gumtree_ID_df['page_url'].values == url)\n",
    "                a = list(a)\n",
    "                a = a[0][0]      \n",
    "                a = int(a)\n",
    "                if gumtree_ID_df.loc[a,'cleaned'] == 1:\n",
    "                    gumtree_df.loc[i,'page_url'] = 'to_delete'\n",
    "                elif gumtree_ID_df.loc[a,'cleaned'] != 1:\n",
    "                    gumtree_ID_df.loc[a,'cleaned'] = 1\n",
    "        for i in range (len(gumtree_df)):\n",
    "            if gumtree_df.loc[i,'page_url'] == 'to_delete':\n",
    "                gumtree_df = gumtree_df.drop(i)\n",
    "        gumtree_ID_df.to_excel(gumtree_ID_xls, index = False)   \n",
    "\n",
    "        print ('ebay changes from ', ebay_opening_len,'to:',len(ebay_df))\n",
    "        print ('gumtree changes from ', gumtree_opening_len,'to:',len(gumtree_df))\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif run =='stolen':\n",
    "\n",
    "        bikereg_opening_len = len(bikereg_df)\n",
    "        sbike_opening_len = len(sbike_df)\n",
    "        \n",
    "#bikereg\n",
    "        bikereg_ID_xls = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/bikereg_IDs.xlsx'\n",
    "        bikereg_ID_df = pd.read_excel(bikereg_ID_xls)\n",
    "        \n",
    "        for i in range (len(bikereg_df)):\n",
    "            url = bikereg_df.loc[i,'page_url']\n",
    "            for x in range (len(bikereg_ID_df)):\n",
    "                if bikereg_ID_df.loc[x,'page_url'] == url and bikereg_ID_df.loc[x,'cleansed'] == 1:\n",
    "                    bikereg_df.loc[i,'page_url'] = 'to_delete'\n",
    "                elif bikereg_ID_df.loc[x,'page_url'] == url and bikereg_ID_df.loc[x,'cleansed'] != 1:\n",
    "                    bikereg_ID_df.loc[x,'cleansed'] = 1\n",
    "\n",
    "        for i in range (len(bikereg_df)):\n",
    "            if bikereg_df.loc[i,'page_url'] == 'to_delete':\n",
    "                bikereg_df = bikereg_df.drop(i)\n",
    "\n",
    "        bikereg_ID_df.to_excel(bikereg_ID_xls, index = False)\n",
    "        \n",
    "#sbike          \n",
    "        sbike_ID_xls = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/sbike_IDs.xlsx'\n",
    "        sbike_ID_df = pd.read_excel(sbike_ID_xls)\n",
    "        \n",
    "        for i in range (len(sbike_df)):\n",
    "            url = sbike_df.loc[i,'page_url']\n",
    "            for x in range (len(sbike_ID_df)):\n",
    "                if sbike_ID_df.loc[x,'page_url'] == url and sbike_ID_df.loc[x,'cleansed'] == 1:\n",
    "                    sbike_df.loc[i,'page_url'] = 'to_delete'\n",
    "                elif sbike_ID_df.loc[x,'page_url'] == url and sbike_ID_df.loc[x,'cleansed'] != 1:\n",
    "                    sbike_ID_df.loc[x,'cleansed'] = 1\n",
    "\n",
    "        for i in range (len(sbike_df)):\n",
    "            if sbike_df.loc[i,'page_url'] == 'to_delete':\n",
    "                sbike_df = sbike_df.drop(i)\n",
    "\n",
    "        sbike_ID_df.to_excel(sbike_ID_xls, index = False)\n",
    "\n",
    "        print ('bikereg (Bike Register) changes from ', bikereg_opening_len,'to:',len(bikereg_df))\n",
    "        print ('sbike (Stolen Bike .co.uk) changes from ', sbike_opening_len,'to:',len(sbike_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e51a122",
   "metadata": {},
   "source": [
    "## location_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77034e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_fn (run):\n",
    "    \n",
    "    global ebay_df\n",
    "    global gumtree_df\n",
    "    global bikereg_df\n",
    "    global sbike_df\n",
    "    \n",
    "    xls_cities = '/Users/neil.collard/Documents/Curious_Projects/Untheft/town_data.xlsx'\n",
    "    cities_df = pd.read_excel(xls_cities)\n",
    "    cities_df = cities_df.apply(lambda x: x.astype(str).str.lower())\n",
    " \n",
    "    if run == 'listed':\n",
    "\n",
    "#ebay\n",
    "        ebay_df.rename(columns={'location': 'old_location'} , inplace=True)\n",
    "        ebay_df.insert(2, \"location\", '')\n",
    "        ebay_df.insert(3, \"latitude\",'')\n",
    "        ebay_df.insert(4, \"longitude\", '')\n",
    "        ebay_df.insert(5, \"county\",'')\n",
    "        ebay_df.reset_index(inplace = True)\n",
    "        ebay_df = ebay_df.drop('level_0', axis=1)\n",
    "\n",
    "        missing_towns = []\n",
    "        matched_towns = []\n",
    "        LB_df = ebay_df\n",
    "        for i in range (len(LB_df)):\n",
    "        #for i in range (20):\n",
    "            town = LB_df.loc[i,'old_location'].split(',')\n",
    "            town = town [0].lstrip().rstrip().lower()\n",
    "            if (cities_df['city'].eq(town)).any():    \n",
    "                a = np.where(cities_df['city'].values == town)\n",
    "                row = a[0][0] \n",
    "                LB_df.loc[i,'location'] = cities_df.loc[row,'clean_city']\n",
    "                LB_df.loc[i,'longitude'] = cities_df.loc[row,'lng']\n",
    "                LB_df.loc[i,'latitude'] = cities_df.loc[row,'lat']\n",
    "                LB_df.loc[i,'county'] = cities_df.loc[row,'county']   \n",
    "            else:\n",
    "                for x in range (len(cities_df)):\n",
    "                    city = cities_df.loc[x,'city']\n",
    "                    match = fuzz.token_set_ratio(town, city)\n",
    "                    match2 = fuzz.ratio(town, city)\n",
    "                    if match >= 90: \n",
    "                        matched_towns.append([match, match2, town,city,x])\n",
    "# fuzz token ratio defines if there is a match\n",
    "# fuzz ratio is then used to determine the best match\n",
    "# this code then orders all of the matches to return the best one\n",
    "                if len(matched_towns) > 0:\n",
    "                    matched_towns = sorted(matched_towns, key=itemgetter(1), reverse = True)  \n",
    "                    row = matched_towns[0][4]\n",
    "#            print (matched_towns[0], row)     \n",
    "                    LB_df.loc[i,'location'] = cities_df.loc[row,'clean_city']\n",
    "                    LB_df.loc[i,'longitude'] = cities_df.loc[row,'lng']\n",
    "                    LB_df.loc[i,'latitude'] = cities_df.loc[row,'lat']\n",
    "                    LB_df.loc[i,'county'] = cities_df.loc[row,'county']                    \n",
    "                    matched_towns = []\n",
    "                else:\n",
    "                    missing_towns.append(town)\n",
    "\n",
    "            #missing towns:\n",
    "        missing_towns = set(missing_towns)            \n",
    "        missing_towns = sorted(missing_towns)\n",
    "\n",
    "        #print ('\\nThere are',len(missing_towns),'missing ebay towns: \\n\\n',missing_towns)   \n",
    "        ebay_df = LB_df   \n",
    "        \n",
    "#gumtree      \n",
    "        \n",
    "        gumtree_df.rename(columns={'location': 'old_location'} , inplace=True)\n",
    "        gumtree_df.insert(2, \"location\", '')\n",
    "        gumtree_df.insert(3, \"latitude\",'')\n",
    "        gumtree_df.insert(4, \"longitude\", '')\n",
    "        gumtree_df.insert(5, \"county\",'')\n",
    "        gumtree_df.reset_index(inplace = True)\n",
    "        gumtree_df = gumtree_df.drop('level_0', axis=1)\n",
    " \n",
    "        missing_towns = []\n",
    "        matched_towns = []\n",
    "        LB_df = gumtree_df\n",
    "\n",
    "        for i in range (len(LB_df)):\n",
    "        #for i in range (2000):\n",
    "            full_town = LB_df.loc[i,'old_location']\n",
    "            town = LB_df.loc[i,'old_location'].split(',')\n",
    "            town = town [0].lstrip().rstrip().lower()\n",
    "\n",
    "            if (cities_df['city'].eq(town)).any():\n",
    "        \n",
    "#returns an array of the rows where the town occurs        \n",
    "                a = np.where(cities_df['city'].values == town)\n",
    "        \n",
    "#this accounts for when there are multiple towns with the same name (it reurns the most populous)        \n",
    "                row = a[0][0] \n",
    "                LB_df.loc[i,'location'] = cities_df.loc[row,'clean_city']\n",
    "                LB_df.loc[i,'longitude'] = cities_df.loc[row,'lng']\n",
    "                LB_df.loc[i,'latitude'] = cities_df.loc[row,'lat']\n",
    "                LB_df.loc[i,'county'] = cities_df.loc[row,'county']\n",
    "\n",
    "# as a second pass I will introduce some fuzzy matching       \n",
    "            else:\n",
    "                for x in range (len(cities_df)):\n",
    "            \n",
    "                    city = cities_df.loc[x,'city']\n",
    "                    match = fuzz.token_set_ratio(full_town, city)\n",
    "                    match2 = fuzz.ratio(full_town, city)\n",
    "                    if match >= 90: \n",
    "                        matched_towns.append([match, match2, full_town,city,x])\n",
    "\n",
    "# fuzz token ratio defines if there is a match\n",
    "# fuzz ratio is then used to determine the best match\n",
    "# this code then orders all of the matches to return the best one\n",
    "\n",
    "                if len(matched_towns) > 0:\n",
    "                    matched_towns = sorted(matched_towns, key=itemgetter(1), reverse = True)  \n",
    "                    row = matched_towns[0][4]\n",
    "#           print (matched_towns[0], row)\n",
    "            \n",
    "                    LB_df.loc[i,'location'] = cities_df.loc[row,'clean_city']\n",
    "                    LB_df.loc[i,'longitude'] = cities_df.loc[row,'lng']\n",
    "                    LB_df.loc[i,'latitude'] = cities_df.loc[row,'lat']\n",
    "                    LB_df.loc[i,'county'] = cities_df.loc[row,'county']\n",
    "                \n",
    "                    matched_towns = []\n",
    "                else:\n",
    "                    missing_towns.append(town)\n",
    "\n",
    "            #missing towns:\n",
    "        missing_towns = set(missing_towns)            \n",
    "        missing_towns = sorted(missing_towns)\n",
    "\n",
    "        \n",
    "        #print ('\\nThere are',len(missing_towns),'missing gumtree towns: \\n\\n',missing_towns)       \n",
    "        gumtree_df = LB_df\n",
    "\n",
    "    if run == 'stolen':\n",
    "        \n",
    "#sbike        \n",
    "        missing_towns = []\n",
    "        matched_towns = []\n",
    "        SB_df = sbike_df\n",
    "        \n",
    "        SB_df.reset_index(inplace = True)    \n",
    "        SB_df = SB_df.drop('level_0', axis=1)\n",
    "        \n",
    "        SB_df = SB_df.apply(lambda x: x.astype(str).str.lower())\n",
    "        SB_df.rename(columns={'location': 'old_location'} , inplace=True)\n",
    "        SB_df.insert(2, \"location\", '')\n",
    "        SB_df.insert(3, \"latitude\",'')\n",
    "        SB_df.insert(4, \"longitude\", '')\n",
    "        SB_df.insert(5, \"county\",'')\n",
    "\n",
    "        for i in range (len(SB_df)):\n",
    "\n",
    "            town = SB_df.loc[i,'old_location'].split(',')\n",
    "            town = town [0].lstrip()\n",
    "\n",
    "            if (cities_df['city'].eq(town)).any():\n",
    "  \n",
    "                a = np.where(cities_df['city'].values == town)\n",
    "                row = a[0][0] #this accounts for when there are multiple towns with the same name (it always returns the most populous)\n",
    "        \n",
    "                SB_df.loc[i,'location'] = cities_df.loc[row,'clean_city']\n",
    "                SB_df.loc[i,'longitude'] = cities_df.loc[row,'lng']\n",
    "                SB_df.loc[i,'latitude'] = cities_df.loc[row,'lat']\n",
    "                SB_df.loc[i,'county'] = cities_df.loc[row,'county']\n",
    "\n",
    "            else:\n",
    "                missing_towns.append(town)\n",
    "\n",
    "        missing_towns = set(missing_towns)\n",
    "        \n",
    "        #print ('There are', len(missing_towns),'missing sbike towns \\n',missing_towns)            \n",
    "        sbike_df = SB_df\n",
    "        \n",
    "#bikereg\n",
    "        missing_towns = []\n",
    "        matched_towns = []\n",
    "        SB_df = bikereg_df        \n",
    "        \n",
    "        SB_df.reset_index(inplace = True)    \n",
    "        SB_df = SB_df.drop('level_0', axis=1)\n",
    "        \n",
    "        SB_df = SB_df.apply(lambda x: x.astype(str).str.lower())\n",
    "        SB_df.rename(columns={'location': 'old_location'} , inplace=True)\n",
    "        SB_df.insert(2, \"location\", '')\n",
    "        SB_df.insert(3, \"latitude\",'')\n",
    "        SB_df.insert(4, \"longitude\", '')\n",
    "        SB_df.insert(5, \"county\",'')\n",
    "\n",
    "        for i in range (len(SB_df)):\n",
    "\n",
    "            town = SB_df.loc[i,'old_location'].split(',')\n",
    "            town = town [0].lstrip()\n",
    "\n",
    "            if (cities_df['city'].eq(town)).any():\n",
    "  \n",
    "                a = np.where(cities_df['city'].values == town)\n",
    "                row = a[0][0] #this accounts for when there are multiple towns with the same name (it always returns the most populous)\n",
    "        \n",
    "                SB_df.loc[i,'location'] = cities_df.loc[row,'clean_city']\n",
    "                SB_df.loc[i,'longitude'] = cities_df.loc[row,'lng']\n",
    "                SB_df.loc[i,'latitude'] = cities_df.loc[row,'lat']\n",
    "                SB_df.loc[i,'county'] = cities_df.loc[row,'county']\n",
    "\n",
    "            else:\n",
    "                missing_towns.append(town)\n",
    "\n",
    "        missing_towns = set(missing_towns)\n",
    "        \n",
    "        #print ('There are', len(missing_towns),'missing bikereg towns \\n',missing_towns)            \n",
    "        bikereg_df = SB_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb1844",
   "metadata": {},
   "source": [
    "# Combine the bikereg and sbike datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bec1cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dfs_fn (run):\n",
    "    global SB_df\n",
    "    if run == 'listed':\n",
    "        SB_df = pd.concat([ebay_df, gumtree_df])\n",
    "        SB_df = SB_df.reset_index()   \n",
    "        SB_df = SB_df.drop('level_0', axis=1) \n",
    "        print ('ebay is:', len(ebay_df),'records')\n",
    "        print ('gumtree is:', len(gumtree_df),'records')\n",
    "        print ('combined dataframe is:', len(SB_df),'records')\n",
    "    if run == 'stolen':\n",
    "        SB_df = pd.concat([bikereg_df, sbike_df])\n",
    "        SB_df = SB_df.reset_index()   \n",
    "        SB_df = SB_df.drop('level_0', axis=1) \n",
    "        print ('bikereg is:', len(bikereg_df),'records')\n",
    "        print ('sbike is:', len(sbike_df),'records')\n",
    "        print ('combined dataframe is:', len(SB_df),'records')   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d17dc8",
   "metadata": {},
   "source": [
    "# >SB< Brands for stolen bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1be961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brand_match_fn(run):\n",
    "\n",
    "    all_brand_names = list(brand_dict.keys())\n",
    "    final_brand_names = list (brand_dict.values())\n",
    "\n",
    "    missing_brands = []\n",
    "    best_brand = []\n",
    "    brand_match_list = []\n",
    "    q = 0\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed  \n",
    "    #for i in range (2000):  \n",
    "        words = str(SB_df.loc[i,'make_orig']).lower()\n",
    "        words2 = str(SB_df.loc[i,'concatination']).lower()\n",
    "\n",
    "    # for each of the bikes this loops through the brand list\n",
    "        for x in range (1,len(all_brand_names)): \n",
    "            brand = all_brand_names[x]\n",
    "            match = fuzz.partial_ratio(words, brand)\n",
    "            if match > 95:\n",
    "                if brand_dict[brand] != 'no match':\n",
    "                    brand_match_list.append ([brand, words, fuzz.ratio(words, brand)])\n",
    "                    \n",
    "                    \n",
    "        if len(brand_match_list)>0:\n",
    "            brand_match_list = sorted(brand_match_list, key=itemgetter(2), reverse = True) \n",
    "            make_clean = str(brand_match_list[0][0])\n",
    "            if len(brand_match_list)>1:\n",
    "                for i in range (len(brand_match_list)):\n",
    "                    make_clean = str(brand_match_list[0][0])\n",
    "                    if make_clean in common_terms:\n",
    "                        brand_match_list.remove(brand_match_list[0])         \n",
    "            SB_df.loc[i,'make_clean'] = brand_dict[make_clean]\n",
    "\n",
    "            if make_clean != brand_dict[make_clean]+' ': \n",
    "                #this allows for the fact that we have a space on the end of the make_clean\n",
    "                dodgy_tag_2 = 'True ' + make_clean + ' is not ' + brand_dict[make_clean]\n",
    "                SB_df.loc[i,'dodgy_tag_2'] = dodgy_tag_2           \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        elif len(brand_match_list)==0:\n",
    "            missing_brands.append(words)\n",
    "\n",
    "            for y in range (1,len(all_brand_names)):\n",
    "                brand = all_brand_names[y]\n",
    "                match2 = fuzz.partial_ratio(words2, brand)\n",
    "\n",
    "                if match2 > 90: \n",
    "                    if brand != 'nan ':\n",
    "                        brand_match_list.append ([brand, words2, fuzz.ratio(words2, brand)])\n",
    "\n",
    "            if len(brand_match_list)>0:\n",
    "                brand_match_list = sorted(brand_match_list, key=itemgetter(2), reverse = True) \n",
    "                make_clean = str(brand_match_list[0][0])\n",
    "                if len(brand_match_list)>1:\n",
    "                    for i in range (len(brand_match_list)):\n",
    "                        make_clean = str(brand_match_list[0][0])\n",
    "                        if make_clean in common_terms:\n",
    "                            brand_match_list.remove(brand_match_list[0]) \n",
    "\n",
    "                SB_df.loc[i,'make_clean'] = brand_dict[make_clean]\n",
    "                if make_clean != brand_dict[make_clean]+' ': \n",
    "                    #this allows for the fact that we have a space on the end of the make_clean\n",
    "                    dodgy_tag_2 = 'True ' + make_clean + ' is not ' + brand_dict[make_clean]\n",
    "                    SB_df.loc[i,'dodgy_tag_2'] = dodgy_tag_2  \n",
    "\n",
    "            elif len(brand_match_list) == 0:\n",
    "                SB_df.loc[i,'make_clean'] = 'no match'\n",
    "                missing_brands.append(words)\n",
    "\n",
    "        brand_match_list = []\n",
    "        best_brand = []\n",
    "\n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_brands)))\n",
    "    #print ('Total missing brands:   ',len(missing_brands))\n",
    "    #print ('Missing brand list:', missing_brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dbf985",
   "metadata": {},
   "source": [
    "# >SB< Models for stolen bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "547b2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_match_fn(run):\n",
    "\n",
    "    all_model_names = list(model_dict.keys())\n",
    "    final_model_names = list (model_dict.values())\n",
    "    missing_models = []\n",
    "    best_model = []\n",
    "    model_match_list = []\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed\n",
    "        words = str(SB_df.loc[i,'concatination']).lower()\n",
    "        for x in range (1,len(all_model_names)): # for each of the bikes this loops through the brand list\n",
    "            model = all_model_names[x]\n",
    "            match = fuzz.partial_ratio(words, model)\n",
    "\n",
    "            if match == 100: #create a list of all perfect matches\n",
    "                model_match_list.append ([model,fuzz.partial_ratio(words, model)])\n",
    "\n",
    "\n",
    "        if len(model_match_list)>0:\n",
    "            model_new = str(model_match_list[0][0])\n",
    "        elif len(model_match_list) == 0:\n",
    "            model_new = 'zz no match '\n",
    "            missing_models.append(words)\n",
    "        SB_df.loc[i,'model_clean'] = model_dict[model_new] #this takes the make and returns the 'clean' version of teh make\n",
    "    \n",
    "        model_match_list = []\n",
    "        best_model = []\n",
    "\n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_models)))\n",
    "    #print ('Total missing models:   ',len(missing_models))\n",
    "    #print ('Missing model list:',missing_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bacd1bc",
   "metadata": {},
   "source": [
    "# >SB< Colours for stolen bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97a608f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colours_match_fn(run):\n",
    "\n",
    "    all_XXXXXX_names = list(colour_dict_2.keys())\n",
    "    final_XXXXXX_names = list (colour_dict_2.values())\n",
    "\n",
    "    missing_XXXXXX = []\n",
    "    best_XXXXXX = []\n",
    "    XXXXXX_match_list = []\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed\n",
    "        words = str(SB_df.loc[i,'colour_orig']).lower().replace('/',' ').replace(',',' ').replace(')',' ').replace('-',' ').replace('(',' ')\n",
    "        word_set = set(words.split())\n",
    "        term_set = set(all_XXXXXX_names)\n",
    "        intersection = (term_set.intersection(word_set))\n",
    "\n",
    "        if len(intersection)>0:\n",
    "            SB_df.loc[i,'colour_clean'] = str(intersection)\n",
    "\n",
    "        elif len(XXXXXX_match_list) == 0:\n",
    "            SB_df.loc[i,'colour_clean'] = 'no match'\n",
    "            missing_XXXXXX.append(words)          \n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_XXXXXX)))\n",
    "    #print ('Total missing models:   ',len(missing_XXXXXX))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93204bf1",
   "metadata": {},
   "source": [
    "# >SB< Type, Gender, Wheel, Electric, Year, Groupset, Material, Brakes, Size, Other terms\n",
    "To make life easier I am (probably) going to break a few coding conventions and just change the dict names and the row to output and leave XXXXX in place for each one. The comment at the top of each code block will explain which term is being updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "513847e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_match_fn(run):\n",
    "\n",
    "    all_XXXXXX_names = list(type_dict.keys())\n",
    "    final_XXXXXX_names = list (type_dict.values())\n",
    "\n",
    "    missing_XXXXXX = []\n",
    "    best_XXXXXX = []\n",
    "    XXXXXX_match_list = []\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed\n",
    "        words = str(SB_df.loc[i,'concatination']).lower()\n",
    "\n",
    "        for x in range (1,len(all_XXXXXX_names)): # for each of the bikes this loops through the brand list\n",
    "            XXXXXX = all_XXXXXX_names[x]\n",
    "            match = fuzz.partial_ratio(words, XXXXXX)\n",
    "\n",
    "            if match == 100: #create a list of all perfect matches\n",
    "                XXXXXX_match_list.append ([XXXXXX,fuzz.partial_ratio(words, XXXXXX)])\n",
    "\n",
    "        if len(XXXXXX_match_list)>0:\n",
    "            XXXXXX_new = str(XXXXXX_match_list[0][0])\n",
    "        elif len(XXXXXX_match_list) == 0:\n",
    "            XXXXXX_new = 'zz no match '\n",
    "            missing_XXXXXX.append(words)\n",
    "        SB_df.loc[i,'type_clean'] = type_dict[XXXXXX_new] #this takes the make and returns the 'clean' version of teh make\n",
    "    \n",
    "        XXXXXX_match_list = []\n",
    "        best_XXXXXX = []\n",
    "\n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_XXXXXX)))\n",
    "    #print ('Total missing models:   ',len(missing_XXXXXX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "474bd329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_match_fn(run):\n",
    "\n",
    "    all_XXXXXX_names = list(gender_dict.keys())\n",
    "    final_XXXXXX_names = list (gender_dict.values())\n",
    "\n",
    "    missing_XXXXXX = []\n",
    "    best_XXXXXX = []\n",
    "    XXXXXX_match_list = []\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed\n",
    "        words = str(SB_df.loc[i,'concatination']).lower()\n",
    "#    print('list of words>', words)\n",
    "        for x in range (1,len(all_XXXXXX_names)): # for each of the bikes this loops through the brand list\n",
    "            XXXXXX = all_XXXXXX_names[x]\n",
    "            match = fuzz.partial_ratio(words, XXXXXX)\n",
    "\n",
    "            if match == 100: #create a list of all perfect matches\n",
    "                XXXXXX_match_list.append ([XXXXXX,fuzz.partial_ratio(words, XXXXXX)])\n",
    "\n",
    "#write back to the df with the clean brand name\n",
    "        if len(XXXXXX_match_list)>0:\n",
    "            XXXXXX_new = str(XXXXXX_match_list[0][0])\n",
    "        elif len(XXXXXX_match_list) == 0:\n",
    "            XXXXXX_new = 'zz no match '\n",
    "            missing_XXXXXX.append(words)\n",
    "        SB_df.loc[i,'gender_clean'] = gender_dict[XXXXXX_new] #this takes the make and returns the 'clean' version of teh make\n",
    "    \n",
    "        XXXXXX_match_list = []\n",
    "        best_XXXXXX = []\n",
    "\n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_XXXXXX)))\n",
    "    #print ('Total missing models:   ',len(missing_XXXXXX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d4bb201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wheel_match_fn(run):\n",
    "\n",
    "    all_XXXXXX_names = list(wheel_dict.keys())\n",
    "    final_XXXXXX_names = list (wheel_dict.values())\n",
    "\n",
    "    missing_XXXXXX = []\n",
    "    best_XXXXXX = []\n",
    "    XXXXXX_match_list = []\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed\n",
    "        words = str(SB_df.loc[i,'concatination']).lower()\n",
    "    #    print('list of words>', words)\n",
    "        for x in range (1,len(all_XXXXXX_names)): # for each of the bikes this loops through the brand list\n",
    "            XXXXXX = all_XXXXXX_names[x]\n",
    "            match = fuzz.partial_ratio(words, XXXXXX)\n",
    "\n",
    "            if match == 100: #create a list of all perfect matches\n",
    "                XXXXXX_match_list.append ([XXXXXX,fuzz.partial_ratio(words, XXXXXX)])\n",
    "\n",
    "    #write back to the df with the clean brand name\n",
    "        if len(XXXXXX_match_list)>0:\n",
    "            XXXXXX_new = str(XXXXXX_match_list[0][0])\n",
    "        elif len(XXXXXX_match_list) == 0:\n",
    "            XXXXXX_new = 'zz no match '\n",
    "            missing_XXXXXX.append(words)\n",
    "        SB_df.loc[i,'wheel_clean'] = wheel_dict[XXXXXX_new] #this takes the make and returns the 'clean' version of teh make\n",
    "\n",
    "        XXXXXX_match_list = []\n",
    "        best_XXXXXX = []\n",
    "\n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_XXXXXX)))\n",
    "    #print ('Total missing models:   ',len(missing_XXXXXX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3c00b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def electric_match_fn(run):\n",
    "\n",
    "    all_XXXXXX_names = list(electric_dict.keys())\n",
    "    final_XXXXXX_names = list (electric_dict.values())\n",
    "\n",
    "    missing_XXXXXX = []\n",
    "    best_XXXXXX = []\n",
    "    XXXXXX_match_list = []\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed\n",
    "        words = str(SB_df.loc[i,'concatination']).lower()\n",
    "    #    print('list of words>', words)\n",
    "        for x in range (1,len(all_XXXXXX_names)): # for each of the bikes this loops through the brand list\n",
    "            XXXXXX = all_XXXXXX_names[x]\n",
    "            match = fuzz.partial_ratio(words, XXXXXX)\n",
    "\n",
    "            if match == 100: #create a list of all perfect matches\n",
    "                XXXXXX_match_list.append ([XXXXXX,fuzz.partial_ratio(words, XXXXXX)])\n",
    "\n",
    "    #write back to the df with the clean brand name\n",
    "        if len(XXXXXX_match_list)>0:\n",
    "            XXXXXX_new = str(XXXXXX_match_list[0][0])\n",
    "        elif len(XXXXXX_match_list) == 0:\n",
    "            XXXXXX_new = 'zz no match '\n",
    "            missing_XXXXXX.append(words)\n",
    "        SB_df.loc[i,'electric_clean'] = electric_dict[XXXXXX_new] #this takes the make and returns the 'clean' version of teh make\n",
    "\n",
    "        XXXXXX_match_list = []\n",
    "        best_XXXXXX = []\n",
    "\n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_XXXXXX)))\n",
    "    #print ('Total missing models:   ',len(missing_XXXXXX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91bb1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_match_fn(run):\n",
    "\n",
    "    all_XXXXXX_names = list(year_dict.keys())\n",
    "    final_XXXXXX_names = list (year_dict.values())\n",
    "\n",
    "    missing_XXXXXX = []\n",
    "    best_XXXXXX = []\n",
    "    XXXXXX_match_list = []\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed\n",
    "        words = str(SB_df.loc[i,'concatination']).lower()\n",
    "    #    print('list of words>', words)\n",
    "        for x in range (1,len(all_XXXXXX_names)): # for each of the bikes this loops through the brand list\n",
    "            XXXXXX = all_XXXXXX_names[x]\n",
    "            match = fuzz.partial_ratio(words, XXXXXX)\n",
    "\n",
    "            if match == 100: #create a list of all perfect matches\n",
    "                XXXXXX_match_list.append ([XXXXXX,fuzz.partial_ratio(words, XXXXXX)])\n",
    "\n",
    "    #write back to the df with the clean brand name\n",
    "        if len(XXXXXX_match_list)>0:\n",
    "            XXXXXX_new = str(XXXXXX_match_list[0][0])\n",
    "        elif len(XXXXXX_match_list) == 0:\n",
    "            XXXXXX_new = 'zz no match '\n",
    "            missing_XXXXXX.append(words)\n",
    "        SB_df.loc[i,'year_clean'] = year_dict[XXXXXX_new] #this takes the make and returns the 'clean' version of teh make\n",
    "\n",
    "        XXXXXX_match_list = []\n",
    "        best_XXXXXX = []\n",
    "\n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_XXXXXX)))\n",
    "    #print ('Total missing models:   ',len(missing_XXXXXX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d28366ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupset_match_fn(run):\n",
    "\n",
    "    all_XXXXXX_names = list(groupset_dict.keys())\n",
    "    final_XXXXXX_names = list (groupset_dict.values())\n",
    "\n",
    "    missing_XXXXXX = []\n",
    "    best_XXXXXX = []\n",
    "    XXXXXX_match_list = []\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed\n",
    "        words = str(SB_df.loc[i,'concatination']).lower()\n",
    "    #    print('list of words>', words)\n",
    "        for x in range (1,len(all_XXXXXX_names)): # for each of the bikes this loops through the brand list\n",
    "            XXXXXX = all_XXXXXX_names[x]\n",
    "            match = fuzz.partial_ratio(words, XXXXXX)\n",
    "\n",
    "            if match == 100: #create a list of all perfect matches\n",
    "                XXXXXX_match_list.append ([XXXXXX,fuzz.partial_ratio(words, XXXXXX)])\n",
    "\n",
    "    #write back to the df with the clean brand name\n",
    "        if len(XXXXXX_match_list)>0:\n",
    "            XXXXXX_new = str(XXXXXX_match_list[0][0])\n",
    "        elif len(XXXXXX_match_list) == 0:\n",
    "            XXXXXX_new = 'zz no match '\n",
    "            missing_XXXXXX.append(words)\n",
    "        SB_df.loc[i,'groupset_clean'] = groupset_dict[XXXXXX_new] #this takes the make and returns the 'clean' version of teh make\n",
    "\n",
    "        XXXXXX_match_list = []\n",
    "        best_XXXXXX = []\n",
    "\n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_XXXXXX)))\n",
    "    #print ('Total missing models:   ',len(missing_XXXXXX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a357ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def material_match_fn(run):\n",
    "\n",
    "    all_XXXXXX_names = list(material_dict.keys())\n",
    "    final_XXXXXX_names = list (material_dict.values())\n",
    "\n",
    "    missing_XXXXXX = []\n",
    "    best_XXXXXX = []\n",
    "    XXXXXX_match_list = []\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed\n",
    "        words = str(SB_df.loc[i,'concatination']).lower()\n",
    "    #    print('list of words>', words)\n",
    "        for x in range (1,len(all_XXXXXX_names)): # for each of the bikes this loops through the brand list\n",
    "            XXXXXX = all_XXXXXX_names[x]\n",
    "            match = fuzz.partial_ratio(words, XXXXXX)\n",
    "\n",
    "            if match == 100: #create a list of all perfect matches\n",
    "                XXXXXX_match_list.append ([XXXXXX,fuzz.partial_ratio(words, XXXXXX)])\n",
    "\n",
    "    #write back to the df with the clean brand name\n",
    "        if len(XXXXXX_match_list)>0:\n",
    "            XXXXXX_new = str(XXXXXX_match_list[0][0])\n",
    "        elif len(XXXXXX_match_list) == 0:\n",
    "            XXXXXX_new = 'zz no match '\n",
    "            missing_XXXXXX.append(words)\n",
    "        SB_df.loc[i,'material_clean'] = material_dict[XXXXXX_new] #this takes the make and returns the 'clean' version of teh make\n",
    "\n",
    "        XXXXXX_match_list = []\n",
    "        best_XXXXXX = []\n",
    "\n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_XXXXXX)))\n",
    "    #print ('Total missing models:   ',len(missing_XXXXXX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05aff884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brakes_match_fn(run):\n",
    "\n",
    "    all_XXXXXX_names = list(brakes_dict.keys())\n",
    "    final_XXXXXX_names = list (brakes_dict.values())\n",
    "\n",
    "    missing_XXXXXX = []\n",
    "    best_XXXXXX = []\n",
    "    XXXXXX_match_list = []\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed\n",
    "        words = str(SB_df.loc[i,'concatination']).lower()\n",
    "    #    print('list of words>', words)\n",
    "        for x in range (1,len(all_XXXXXX_names)): # for each of the bikes this loops through the brand list\n",
    "            XXXXXX = all_XXXXXX_names[x]\n",
    "            match = fuzz.partial_ratio(words, XXXXXX)\n",
    "\n",
    "            if match == 100: #create a list of all perfect matches\n",
    "                XXXXXX_match_list.append ([XXXXXX,fuzz.partial_ratio(words, XXXXXX)])\n",
    "\n",
    "    #write back to the df with the clean brand name\n",
    "        if len(XXXXXX_match_list)>0:\n",
    "            XXXXXX_new = str(XXXXXX_match_list[0][0])\n",
    "        elif len(XXXXXX_match_list) == 0:\n",
    "            XXXXXX_new = 'zz no match '\n",
    "            missing_XXXXXX.append(words)\n",
    "        SB_df.loc[i,'brakes_clean'] = brakes_dict[XXXXXX_new] #this takes the make and returns the 'clean' version of teh make\n",
    "\n",
    "        XXXXXX_match_list = []\n",
    "        best_XXXXXX = []\n",
    "\n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_XXXXXX)))\n",
    "    #print ('Total missing models:   ',len(missing_XXXXXX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6db129cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_match_fn(run):\n",
    "\n",
    "    all_XXXXXX_names = list(size_dict.keys())\n",
    "    final_XXXXXX_names = list (size_dict.values())\n",
    "\n",
    "    missing_XXXXXX = []\n",
    "    best_XXXXXX = []\n",
    "    XXXXXX_match_list = []\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed\n",
    "        words = str(SB_df.loc[i,'concatination']).lower()\n",
    "    #    print('list of words>', words)\n",
    "        for x in range (1,len(all_XXXXXX_names)): # for each of the bikes this loops through the brand list\n",
    "            XXXXXX = all_XXXXXX_names[x]\n",
    "            match = fuzz.partial_ratio(words, XXXXXX)\n",
    "\n",
    "            if match == 100: #create a list of all perfect matches\n",
    "                XXXXXX_match_list.append ([XXXXXX,fuzz.partial_ratio(words, XXXXXX)])\n",
    "\n",
    "    #write back to the df with the clean brand name\n",
    "        if len(XXXXXX_match_list)>0:\n",
    "            XXXXXX_new = str(XXXXXX_match_list[0][0])\n",
    "        elif len(XXXXXX_match_list) == 0:\n",
    "            XXXXXX_new = 'zz no match '\n",
    "            missing_XXXXXX.append(words)\n",
    "        SB_df.loc[i,'size_clean'] = size_dict[XXXXXX_new] #this takes the make and returns the 'clean' version of teh make\n",
    "\n",
    "        XXXXXX_match_list = []\n",
    "        best_XXXXXX = []\n",
    "\n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_XXXXXX)))\n",
    "    #print ('Total missing models:   ',len(missing_XXXXXX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b689dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_match_fn(run):\n",
    "\n",
    "    all_XXXXXX_names = list(other_terms_dict.keys())\n",
    "    final_XXXXXX_names = list (other_terms_dict.values())\n",
    "\n",
    "    missing_XXXXXX = []\n",
    "    best_XXXXXX = []\n",
    "    XXXXXX_match_list = []\n",
    "\n",
    "    for i in range (len(SB_df)):  # This cycles through all of the bikes listed\n",
    "        words = str(SB_df.loc[i,'concatination']).lower()\n",
    "        word_set = set(words.split())\n",
    "        term_set = set(all_XXXXXX_names)\n",
    "        intersection = (term_set.intersection(word_set))\n",
    "    #    print (intersection)\n",
    "    #    print (len(intersection))        \n",
    "\n",
    "    #write back to the df with the clean brand name\n",
    "        if len(intersection)>0:\n",
    "            SB_df.loc[i,'other_terms_clean'] = str(intersection)\n",
    "            SB_df.loc[i,'other_terms_count'] = len(intersection)\n",
    "\n",
    "\n",
    "        elif len(XXXXXX_match_list) == 0:\n",
    "            SB_df.loc[i,'other_terms_clean'] = 0\n",
    "            SB_df.loc[i,'other_terms_count'] = 0\n",
    "\n",
    "\n",
    "    #print ('Total records looked at:',(len(SB_df)))\n",
    "    #print ('Successful matches:     ',(len(SB_df)-len(missing_XXXXXX)))\n",
    "    #print ('Total missing models:   ',len(missing_XXXXXX))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1d449f",
   "metadata": {},
   "source": [
    "# Cleaning date data\n",
    "Making everything datetime.date object (no time element) so that we can better track date averages etc to understand how effectively we are identifying stolen bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22c1704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_tidy_fn(run):\n",
    "    SB_df['date_reported'] = pd.to_datetime(SB_df['date_reported']).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef0fc0",
   "metadata": {},
   "source": [
    "# Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8c9c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_save_fn (run):\n",
    "    if run == 'listed':\n",
    "        today = datetime.today().strftime(\"%H:%M_%d.%m.%y\")\n",
    "        batch_xls = '/Users/neil.collard/Documents/Curious_Projects/untheft/live/daily/Listed_bike_CLEAN_Daily_'+today+'.xlsx'\n",
    "        SB_df.to_excel(batch_xls, index = False)\n",
    "        \n",
    "        god_log_xls = '/Users/neil.collard/Documents/Curious_Projects/untheft/live/God_Save_Log.xlsx'\n",
    "        god_log_df = pd.read_excel(god_log_xls)\n",
    "        new_god_log = pd.DataFrame({\n",
    "        \"date_created\" : [datetime.now().date().strftime(\"%Y.%m.%d\")],\n",
    "        \"time_created\" : [datetime.now().time().strftime(\"%Hh%Mm\")],\n",
    "        \"filename\" : [batch_xls],\n",
    "        \"type\" : [run],\n",
    "        \"file_length\" : [len(SB_df)],\n",
    "         \"live_or_master\" : ['DAILY']})\n",
    "        god_log_df = pd.concat([god_log_df,new_god_log])\n",
    "        god_log_df.to_excel(god_log_xls, index = False)          \n",
    "        \n",
    "\n",
    "    if run =='stolen':\n",
    "        today = datetime.today().strftime(\"%H:%M_%d.%m.%y\")\n",
    "        batch_xls = '/Users/neil.collard/Documents/Curious_Projects/untheft/live/daily/stolen_bike_CLEAN_Daily_'+today+'.xlsx'\n",
    "        SB_df.to_excel(batch_xls, index = False)\n",
    "\n",
    "        god_log_xls = '/Users/neil.collard/Documents/Curious_Projects/untheft/live/God_Save_Log.xlsx'\n",
    "        god_log_df = pd.read_excel(god_log_xls)\n",
    "        new_god_log = pd.DataFrame({\n",
    "        \"date_created\" : [datetime.now().date().strftime(\"%Y.%m.%d\")],\n",
    "        \"time_created\" : [datetime.now().time().strftime(\"%Hh%Mm\")],\n",
    "        \"filename\" : [batch_xls],\n",
    "        \"type\" : [run],\n",
    "        \"file_length\" : [len(SB_df)],\n",
    "        \"live_or_master\" : ['DAILY']})\n",
    "        god_log_df = pd.concat([god_log_df,new_god_log])\n",
    "        god_log_df.to_excel(god_log_xls, index = False)     \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b50881c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_master_fn(run):\n",
    "\n",
    "    \n",
    "    if run == 'listed':\n",
    "        master_xls_filename = '/Users/neil.collard/Documents/Curious_Projects/untheft/live/listed_clean_MASTER.xlsx'\n",
    "        master_df = pd.read_excel(master_xls_filename)\n",
    "        new_df = pd.concat([master_df, SB_df])\n",
    "        new_df.to_excel(master_xls_filename, index = False)   \n",
    "        \n",
    "        #god log function\n",
    "        god_log_xls = '/Users/neil.collard/Documents/Curious_Projects/untheft/live/God_Save_Log.xlsx'\n",
    "        god_log_df = pd.read_excel(god_log_xls)\n",
    "        new_god_log = pd.DataFrame({\n",
    "        \"date_created\" : [datetime.now().date().strftime(\"%Y.%m.%d\")],\n",
    "        \"time_created\" : [datetime.now().time().strftime(\"%Hh%Mm\")],\n",
    "        \"filename\" : [master_xls_filename],\n",
    "        \"type\" : ['LISTED'],\n",
    "        \"file_length\" : [len(new_df)],\n",
    "        \"live_or_master\" : ['master']})\n",
    "        god_log_df = pd.concat([god_log_df,new_god_log])\n",
    "        god_log_df.to_excel(god_log_xls, index = False)   \n",
    "\n",
    "      \n",
    "    if run =='stolen':\n",
    "        master_xls_filename = '/Users/neil.collard/Documents/Curious_Projects/untheft/live/stolen_clean_MASTER.xlsx'\n",
    "        master_df = pd.read_excel(master_xls_filename)\n",
    "        new_df = pd.concat([master_df, SB_df])\n",
    "        new_df.to_excel(master_xls_filename, index = False)   \n",
    "\n",
    "        #god log function\n",
    "        god_log_xls = '/Users/neil.collard/Documents/Curious_Projects/untheft/live/God_Save_Log.xlsx'\n",
    "        god_log_df = pd.read_excel(god_log_xls)\n",
    "        new_god_log = pd.DataFrame({\n",
    "        \"date_created\" : [datetime.now().date().strftime(\"%Y.%m.%d\")],\n",
    "        \"time_created\" : [datetime.now().time().strftime(\"%Hh%Mm\")],\n",
    "        \"filename\" : [master_xls_filename],\n",
    "        \"type\" : [run],\n",
    "        \"file_length\" : [len(new_df)],\n",
    "        \"live_or_master\" : ['master']})\n",
    "        \n",
    "        god_log_df = pd.concat([god_log_df,new_god_log])\n",
    "        god_log_df.to_excel(god_log_xls, index = False)   \n",
    "        \n",
    "        \n",
    "        \n",
    "    print('Files saved successfully at:', datetime.today())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ef0db",
   "metadata": {},
   "source": [
    "# Functions of functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40239ac",
   "metadata": {},
   "source": [
    "## ebay_full_run_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12b7e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebay_full_run_fn (pages):\n",
    "    url = 'https://www.ebay.co.uk/sch/i.html?_from=R40&_nkw=bicycle&_sacat=0&Department=Unisex%2520Adults%7CMen%7CWomen&_dcat=177831&rt=nc&LH_ItemCondition=1500%7C2500%7C3000%7C7000&_ipg=240'\n",
    "    xls_raw = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/' + run + '_raw.xlsx'\n",
    "    xls_ID = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/' + run + '_IDs.xlsx'\n",
    "    xls_log = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/' + run + '_log.xlsx'\n",
    "\n",
    "    print ('\\n-----',run,'----- \\nStarted at:',datetime.today())   \n",
    "    t=0\n",
    "    global raw_df\n",
    "    raw_df = pd.read_excel(xls_raw)\n",
    "    print ('opening raw data length', len(raw_df))\n",
    "    \n",
    "    index_url_list_fn(url,pages)\n",
    "    all_detail_urls_fn (index_url_list)\n",
    "    ID_fn (xls_ID, all_detail_urls)\n",
    "    urls_to_get_fn (ID_df)\n",
    "    global each_url\n",
    "    for each_url in target_IDs:\n",
    "        t = t+1\n",
    "        #3print (t,'  ',each_url)\n",
    "        get_detail_soup_fn(each_url)\n",
    "        ebay_detail_getter_fn(product_soup)\n",
    "        write_data_fn(data)\n",
    "    status = 'success'\n",
    "    update_ID (status)\n",
    "    raw_df.to_excel(xls_raw, index = False)   \n",
    "    print ('closing raw data length', len(raw_df))\n",
    "    log_fn(run)\n",
    "    print ('-----',run,'----- \\nCompleted at:',datetime.today(),'\\n')           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c23455",
   "metadata": {},
   "source": [
    "## gumtree_full_run_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bc1a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumtree_full_run_fn (pages):\n",
    "    url = 'https://www.gumtree.com/search?search_category=bicycles&search_location=uk&q=bicycle'\n",
    "    xls_raw = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/' + run + '_raw.xlsx'\n",
    "    xls_ID = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/' + run + '_IDs.xlsx'\n",
    "    xls_log = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/' + run + '_log.xlsx'\n",
    "    \n",
    "    print ('\\n-----',run,'----- \\nStarted at:',datetime.today())    \n",
    "    \n",
    "    global raw_df\n",
    "    raw_df = pd.read_excel(xls_raw)\n",
    "    print ('opening raw data length', len(raw_df))    \n",
    "    \n",
    "    index_url_list_fn(url,pages)\n",
    "    print ('index_url_list length:',len(index_url_list))\n",
    "    all_detail_urls_fn (index_url_list)\n",
    "    print ('all_detail_urls:',len(all_detail_urls))\n",
    "    ID_fn (xls_ID, all_detail_urls)\n",
    "    urls_to_get_fn (ID_df)\n",
    "    print ('all_detail_urls:',len(all_detail_urls))\n",
    "    print ('target_IDs:',len(target_IDs))\n",
    "       \n",
    "\n",
    "    global each_url\n",
    "    for each_url in target_IDs:\n",
    "        #print (each_url)\n",
    "        time.sleep(random.randint(1,4))\n",
    "        get_detail_soup_fn(each_url)\n",
    "        gumtree_detail_getter_fn(product_soup)\n",
    "        write_data_fn(data)\n",
    "    status = 'success'\n",
    "    update_ID (status)\n",
    "    raw_df.to_excel(xls_raw, index = False)   \n",
    "    print ('closing raw data length', len(raw_df))\n",
    "    log_fn(run)\n",
    "    print ('-----',run,'----- \\nCompleted at:',datetime.today(),'\\n')          \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae0044",
   "metadata": {},
   "source": [
    "## sbike_full_run_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65e0d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbike_full_run_fn (pages):\n",
    "\n",
    "    url = 'https://stolen-bikes.co.uk/stolen-bikes/'\n",
    "    xls_raw = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/' + run + '_raw.xlsx'\n",
    "    xls_ID = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/' + run + '_IDs.xlsx'\n",
    "    xls_log = '/Users/neil.collard/Documents/Curious_Projects/Untheft/live/' + run + '_log.xlsx'\n",
    "\n",
    "    print ('\\n-----',run,'----- \\nStarted at:',datetime.today())   \n",
    "    \n",
    "    global raw_df\n",
    "    raw_df = pd.read_excel(xls_raw)\n",
    "    print ('opening raw data length', len(raw_df))\n",
    "\n",
    "    index_url_list_fn(url,pages)\n",
    "    all_detail_urls_fn (index_url_list)\n",
    "    ID_fn (xls_ID, all_detail_urls)\n",
    "    urls_to_get_fn (ID_df)\n",
    "    global each_url\n",
    "    for each_url in target_IDs:\n",
    "        get_detail_soup_fn(each_url)\n",
    "        sbike_detail_getter_fn(product_soup)\n",
    "        write_data_fn(data)\n",
    "    status = 'success'\n",
    "    update_ID (status)\n",
    "    raw_df.to_excel(xls_raw, index = False)   \n",
    "    print ('closing raw data length', len(raw_df))\n",
    "    log_fn(run)\n",
    "    print ('-----',run,'----- \\nCompleted at:',datetime.today(),'\\n')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6bfd63",
   "metadata": {},
   "source": [
    "# MAIN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66552cc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- ebay ----- \n",
      "Started at: 2023-11-02 10:09:28.263784\n",
      "opening raw data length 72613\n",
      "length of all_detail_urls is: 253\n",
      "length of all_detail_urls is: 509\n",
      "length of all_detail_urls is: 765\n",
      "length of all_detail_urls is: 1021\n",
      "all_detail_urls length: 1021\n",
      "Total number of IDs looks at:  1021\n",
      "Total number of NEW IDs:  151\n",
      "Total number of known_IDs 870\n",
      "Length of ID_df 74431\n",
      "getting details for ebay\n",
      "Target_ID length before is 0\n",
      "Target_ID length after is 151\n"
     ]
    }
   ],
   "source": [
    "# Scraping data\n",
    "\n",
    "today = datetime.today()\n",
    "begin_process_time = today.strftime(\"%H:%M_%d.%m.%y\")\n",
    "\n",
    "#pause = (random.randint(120,1000))\n",
    "#print ('Pausing for ',pause, 'seconds')\n",
    "#time.sleep((pause))\n",
    "\n",
    "# ---ebay---\n",
    "pages = 5\n",
    "run = 'ebay'\n",
    "ebay_full_run_fn (pages)\n",
    "\n",
    "\n",
    "# ---gumtree---\n",
    "#pages = 15\n",
    "#run = 'gumtree'\n",
    "#gumtree_full_run_fn (pages)\n",
    "\n",
    "# ---sbike---\n",
    "pages = 5\n",
    "run = 'sbike'\n",
    "sbike_full_run_fn (pages)\n",
    "\n",
    "# Model Parsing\n",
    "\n",
    "run = 'listed'\n",
    "\n",
    "load_data_fn(run)\n",
    "print ('load_data_fn \\u2713 ')\n",
    "prepare_df_fn(run)\n",
    "print ('prepare_df_fn \\u2713')\n",
    "identify_IDs_fn(run)\n",
    "print ('identify_IDs_fn \\u2713')\n",
    "location_fn(run)\n",
    "print ('location_fn \\u2713')\n",
    "combine_dfs_fn (run)\n",
    "print ('combine_dfs_fn \\u2713')\n",
    "brand_match_fn(run)\n",
    "model_match_fn(run)\n",
    "colours_match_fn(run)\n",
    "type_match_fn(run)\n",
    "gender_match_fn(run)\n",
    "wheel_match_fn(run)\n",
    "electric_match_fn(run)\n",
    "year_match_fn(run)\n",
    "groupset_match_fn(run)\n",
    "material_match_fn(run)\n",
    "brakes_match_fn(run)\n",
    "size_match_fn(run)\n",
    "other_match_fn(run)\n",
    "print ('model matching functions \\u2713')\n",
    "date_tidy_fn(run)\n",
    "print ('date_tidy_fn \\u2713')\n",
    "batch_save_fn (run)\n",
    "print ('batch save fn \\u2713')\n",
    "update_master_fn(run)\n",
    "print (run, 'COMPLETE')\n",
    "\n",
    "run = 'stolen'\n",
    "\n",
    "load_data_fn(run)\n",
    "print ('load_data_fn \\u2713 ')\n",
    "prepare_df_fn(run)\n",
    "print ('prepare_df_fn \\u2713')\n",
    "identify_IDs_fn(run)\n",
    "print ('identify_IDs_fn \\u2713')\n",
    "location_fn(run)\n",
    "print ('location_fn \\u2713')\n",
    "combine_dfs_fn (run)\n",
    "print ('combine_dfs_fn \\u2713')\n",
    "brand_match_fn(run)\n",
    "model_match_fn(run)\n",
    "colours_match_fn(run)\n",
    "type_match_fn(run)\n",
    "gender_match_fn(run)\n",
    "wheel_match_fn(run)\n",
    "electric_match_fn(run)\n",
    "year_match_fn(run)\n",
    "groupset_match_fn(run)\n",
    "material_match_fn(run)\n",
    "brakes_match_fn(run)\n",
    "size_match_fn(run)\n",
    "other_match_fn(run)\n",
    "print ('model matching functions \\u2713')\n",
    "date_tidy_fn(run)\n",
    "print ('date_tidy_fn \\u2713')\n",
    "batch_save_fn (run)\n",
    "print ('batch save fn \\u2713')\n",
    "update_master_fn(run)\n",
    "\n",
    "\n",
    "print ('Process started at: ', begin_process_time)\n",
    "print ('Process completed at: ', datetime.today().strftime(\"%H:%M_%d.%m.%y\"))\n",
    "print ('ALL COMPLETE (baby)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec1f99b-5d6c-4aba-af9a-0ec719417433",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Code updated on 18.1.23')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
